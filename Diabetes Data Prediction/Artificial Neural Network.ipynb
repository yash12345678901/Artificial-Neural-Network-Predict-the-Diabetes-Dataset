{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: This program detects if a person have diabetes or not\n",
    "\n",
    "# Load Libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(r'C:\\Users\\Yash Kumar\\Pictures\\diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "5            5      116             74              0        0  25.6   \n",
       "6            3       78             50             32       88  31.0   \n",
       "7           10      115              0              0        0  35.3   \n",
       "8            2      197             70             45      543  30.5   \n",
       "9            8      125             96              0        0   0.0   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  \n",
       "5                     0.201   30        0  \n",
       "6                     0.248   26        1  \n",
       "7                     0.134   29        0  \n",
       "8                     0.158   53        1  \n",
       "9                     0.232   54        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 10 row of dataset\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the shape(Number of rows and columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates and remove them\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the shape(Number of rows and columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the number of missing data for each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the data into array\n",
    "dataset = df.values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all of the rows from the first 10 column dataset\n",
    "x = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
       "        0.48333333],\n",
       "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
       "        0.16666667],\n",
       "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
       "        0.18333333],\n",
       "       ...,\n",
       "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
       "        0.15      ],\n",
       "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
       "        0.43333333],\n",
       "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
       "        0.03333333]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precess the data\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scale = min_max_scaler.fit_transform(x)\n",
    "x_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scale, y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential([\n",
    "    Dense(12, activation = 'relu', input_shape = (8,)),\n",
    "    Dense(15, activation = 'relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yash Kumar\\anaconda4\\envs\\py3-TF1\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(\n",
    "     optimizer = 'sgd',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yash Kumar\\anaconda4\\envs\\py3-TF1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 491 samples, validate on 123 samples\n",
      "Epoch 1/1000\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.7170 - accuracy: 0.3585 - val_loss: 0.7110 - val_accuracy: 0.3577\n",
      "Epoch 2/1000\n",
      "491/491 [==============================] - 0s 44us/step - loss: 0.7078 - accuracy: 0.3870 - val_loss: 0.7031 - val_accuracy: 0.3821\n",
      "Epoch 3/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.7008 - accuracy: 0.4399 - val_loss: 0.6964 - val_accuracy: 0.4634\n",
      "Epoch 4/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.6949 - accuracy: 0.4888 - val_loss: 0.6910 - val_accuracy: 0.5691\n",
      "Epoch 5/1000\n",
      "491/491 [==============================] - 0s 39us/step - loss: 0.6900 - accuracy: 0.5519 - val_loss: 0.6864 - val_accuracy: 0.6504\n",
      "Epoch 6/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.6858 - accuracy: 0.6191 - val_loss: 0.6823 - val_accuracy: 0.6423\n",
      "Epoch 7/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.6821 - accuracy: 0.6314 - val_loss: 0.6787 - val_accuracy: 0.6179\n",
      "Epoch 8/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6789 - accuracy: 0.6375 - val_loss: 0.6756 - val_accuracy: 0.6260\n",
      "Epoch 9/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6762 - accuracy: 0.6578 - val_loss: 0.6729 - val_accuracy: 0.6423\n",
      "Epoch 10/1000\n",
      "491/491 [==============================] - 0s 42us/step - loss: 0.6739 - accuracy: 0.6538 - val_loss: 0.6707 - val_accuracy: 0.6585\n",
      "Epoch 11/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.6719 - accuracy: 0.6517 - val_loss: 0.6688 - val_accuracy: 0.6585\n",
      "Epoch 12/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6702 - accuracy: 0.6497 - val_loss: 0.6670 - val_accuracy: 0.6585\n",
      "Epoch 13/1000\n",
      "491/491 [==============================] - 0s 17us/step - loss: 0.6686 - accuracy: 0.6477 - val_loss: 0.6654 - val_accuracy: 0.6585\n",
      "Epoch 14/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6672 - accuracy: 0.6477 - val_loss: 0.6639 - val_accuracy: 0.6585\n",
      "Epoch 15/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.6657 - accuracy: 0.6477 - val_loss: 0.6626 - val_accuracy: 0.6585\n",
      "Epoch 16/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6645 - accuracy: 0.6477 - val_loss: 0.6614 - val_accuracy: 0.6585\n",
      "Epoch 17/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.6634 - accuracy: 0.6477 - val_loss: 0.6603 - val_accuracy: 0.6585\n",
      "Epoch 18/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6623 - accuracy: 0.6477 - val_loss: 0.6594 - val_accuracy: 0.6585\n",
      "Epoch 19/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.6614 - accuracy: 0.6477 - val_loss: 0.6585 - val_accuracy: 0.6585\n",
      "Epoch 20/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6605 - accuracy: 0.6477 - val_loss: 0.6576 - val_accuracy: 0.6504\n",
      "Epoch 21/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6597 - accuracy: 0.6477 - val_loss: 0.6568 - val_accuracy: 0.6504\n",
      "Epoch 22/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6589 - accuracy: 0.6477 - val_loss: 0.6561 - val_accuracy: 0.6504\n",
      "Epoch 23/1000\n",
      "491/491 [==============================] - 0s 17us/step - loss: 0.6582 - accuracy: 0.6477 - val_loss: 0.6554 - val_accuracy: 0.6504\n",
      "Epoch 24/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6575 - accuracy: 0.6477 - val_loss: 0.6548 - val_accuracy: 0.6504\n",
      "Epoch 25/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.6569 - accuracy: 0.6477 - val_loss: 0.6542 - val_accuracy: 0.6504\n",
      "Epoch 26/1000\n",
      "491/491 [==============================] - 0s 55us/step - loss: 0.6564 - accuracy: 0.6477 - val_loss: 0.6536 - val_accuracy: 0.6504\n",
      "Epoch 27/1000\n",
      "491/491 [==============================] - 0s 40us/step - loss: 0.6558 - accuracy: 0.6477 - val_loss: 0.6530 - val_accuracy: 0.6504\n",
      "Epoch 28/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.6552 - accuracy: 0.6477 - val_loss: 0.6525 - val_accuracy: 0.6504\n",
      "Epoch 29/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6546 - accuracy: 0.6477 - val_loss: 0.6519 - val_accuracy: 0.6504\n",
      "Epoch 30/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6541 - accuracy: 0.6477 - val_loss: 0.6515 - val_accuracy: 0.6504\n",
      "Epoch 31/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6536 - accuracy: 0.6477 - val_loss: 0.6510 - val_accuracy: 0.6504\n",
      "Epoch 32/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.6532 - accuracy: 0.6477 - val_loss: 0.6505 - val_accuracy: 0.6504\n",
      "Epoch 33/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6527 - accuracy: 0.6477 - val_loss: 0.6501 - val_accuracy: 0.6504\n",
      "Epoch 34/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6523 - accuracy: 0.6477 - val_loss: 0.6497 - val_accuracy: 0.6504\n",
      "Epoch 35/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6519 - accuracy: 0.6477 - val_loss: 0.6492 - val_accuracy: 0.6504\n",
      "Epoch 36/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6514 - accuracy: 0.6477 - val_loss: 0.6489 - val_accuracy: 0.6504\n",
      "Epoch 37/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6510 - accuracy: 0.6477 - val_loss: 0.6485 - val_accuracy: 0.6504\n",
      "Epoch 38/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6506 - accuracy: 0.6477 - val_loss: 0.6481 - val_accuracy: 0.6504\n",
      "Epoch 39/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6502 - accuracy: 0.6477 - val_loss: 0.6478 - val_accuracy: 0.6504\n",
      "Epoch 40/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6499 - accuracy: 0.6477 - val_loss: 0.6474 - val_accuracy: 0.6504\n",
      "Epoch 41/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.6495 - accuracy: 0.6477 - val_loss: 0.6470 - val_accuracy: 0.6504\n",
      "Epoch 42/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6491 - accuracy: 0.6477 - val_loss: 0.6467 - val_accuracy: 0.6504\n",
      "Epoch 43/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.6487 - accuracy: 0.6477 - val_loss: 0.6464 - val_accuracy: 0.6504\n",
      "Epoch 44/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6484 - accuracy: 0.6477 - val_loss: 0.6461 - val_accuracy: 0.6504\n",
      "Epoch 45/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.6481 - accuracy: 0.6477 - val_loss: 0.6458 - val_accuracy: 0.6504\n",
      "Epoch 46/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.6477 - accuracy: 0.6477 - val_loss: 0.6454 - val_accuracy: 0.6504\n",
      "Epoch 47/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.6473 - accuracy: 0.6477 - val_loss: 0.6451 - val_accuracy: 0.6504\n",
      "Epoch 48/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6470 - accuracy: 0.6477 - val_loss: 0.6449 - val_accuracy: 0.6504\n",
      "Epoch 49/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.6466 - accuracy: 0.6477 - val_loss: 0.6446 - val_accuracy: 0.6504\n",
      "Epoch 50/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6463 - accuracy: 0.6477 - val_loss: 0.6443 - val_accuracy: 0.6504\n",
      "Epoch 51/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6460 - accuracy: 0.6477 - val_loss: 0.6440 - val_accuracy: 0.6504\n",
      "Epoch 52/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.6456 - accuracy: 0.6477 - val_loss: 0.6437 - val_accuracy: 0.6504\n",
      "Epoch 53/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.6453 - accuracy: 0.6477 - val_loss: 0.6434 - val_accuracy: 0.6504\n",
      "Epoch 54/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6450 - accuracy: 0.6477 - val_loss: 0.6431 - val_accuracy: 0.6504\n",
      "Epoch 55/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.6446 - accuracy: 0.6477 - val_loss: 0.6429 - val_accuracy: 0.6504\n",
      "Epoch 56/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.6444 - accuracy: 0.6477 - val_loss: 0.6426 - val_accuracy: 0.6504\n",
      "Epoch 57/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.6440 - accuracy: 0.6477 - val_loss: 0.6424 - val_accuracy: 0.6504\n",
      "Epoch 58/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6438 - accuracy: 0.6477 - val_loss: 0.6421 - val_accuracy: 0.6504\n",
      "Epoch 59/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.6434 - accuracy: 0.6477 - val_loss: 0.6418 - val_accuracy: 0.6504\n",
      "Epoch 60/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6432 - accuracy: 0.6477 - val_loss: 0.6415 - val_accuracy: 0.6504\n",
      "Epoch 61/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6428 - accuracy: 0.6477 - val_loss: 0.6413 - val_accuracy: 0.6504\n",
      "Epoch 62/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6425 - accuracy: 0.6477 - val_loss: 0.6410 - val_accuracy: 0.6504\n",
      "Epoch 63/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.6422 - accuracy: 0.6477 - val_loss: 0.6407 - val_accuracy: 0.6504\n",
      "Epoch 64/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6419 - accuracy: 0.6477 - val_loss: 0.6405 - val_accuracy: 0.6504\n",
      "Epoch 65/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.6416 - accuracy: 0.6477 - val_loss: 0.6402 - val_accuracy: 0.6504\n",
      "Epoch 66/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.6413 - accuracy: 0.6477 - val_loss: 0.6400 - val_accuracy: 0.6504\n",
      "Epoch 67/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6410 - accuracy: 0.6477 - val_loss: 0.6397 - val_accuracy: 0.6504\n",
      "Epoch 68/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6407 - accuracy: 0.6477 - val_loss: 0.6395 - val_accuracy: 0.6504\n",
      "Epoch 69/1000\n",
      "491/491 [==============================] - 0s 38us/step - loss: 0.6404 - accuracy: 0.6477 - val_loss: 0.6392 - val_accuracy: 0.6504\n",
      "Epoch 70/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6401 - accuracy: 0.6477 - val_loss: 0.6390 - val_accuracy: 0.6504\n",
      "Epoch 71/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6398 - accuracy: 0.6477 - val_loss: 0.6387 - val_accuracy: 0.6504\n",
      "Epoch 72/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6396 - accuracy: 0.6477 - val_loss: 0.6385 - val_accuracy: 0.6504\n",
      "Epoch 73/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6392 - accuracy: 0.6477 - val_loss: 0.6382 - val_accuracy: 0.6504\n",
      "Epoch 74/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6389 - accuracy: 0.6477 - val_loss: 0.6380 - val_accuracy: 0.6504\n",
      "Epoch 75/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6387 - accuracy: 0.6477 - val_loss: 0.6378 - val_accuracy: 0.6504\n",
      "Epoch 76/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6383 - accuracy: 0.6477 - val_loss: 0.6375 - val_accuracy: 0.6504\n",
      "Epoch 77/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6381 - accuracy: 0.6477 - val_loss: 0.6373 - val_accuracy: 0.6504\n",
      "Epoch 78/1000\n",
      "491/491 [==============================] - 0s 43us/step - loss: 0.6377 - accuracy: 0.6477 - val_loss: 0.6370 - val_accuracy: 0.6504\n",
      "Epoch 79/1000\n",
      "491/491 [==============================] - 0s 34us/step - loss: 0.6375 - accuracy: 0.6477 - val_loss: 0.6368 - val_accuracy: 0.6504\n",
      "Epoch 80/1000\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.6371 - accuracy: 0.6477 - val_loss: 0.6365 - val_accuracy: 0.6504\n",
      "Epoch 81/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6368 - accuracy: 0.6477 - val_loss: 0.6363 - val_accuracy: 0.6504\n",
      "Epoch 82/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6365 - accuracy: 0.6477 - val_loss: 0.6361 - val_accuracy: 0.6504\n",
      "Epoch 83/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6362 - accuracy: 0.6477 - val_loss: 0.6358 - val_accuracy: 0.6504\n",
      "Epoch 84/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6359 - accuracy: 0.6477 - val_loss: 0.6356 - val_accuracy: 0.6504\n",
      "Epoch 85/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6355 - accuracy: 0.6477 - val_loss: 0.6353 - val_accuracy: 0.6504\n",
      "Epoch 86/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.6352 - accuracy: 0.6477 - val_loss: 0.6351 - val_accuracy: 0.6504\n",
      "Epoch 87/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.6348 - accuracy: 0.6477 - val_loss: 0.6349 - val_accuracy: 0.6504\n",
      "Epoch 88/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.6345 - accuracy: 0.6477 - val_loss: 0.6347 - val_accuracy: 0.6504\n",
      "Epoch 89/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6342 - accuracy: 0.6477 - val_loss: 0.6344 - val_accuracy: 0.6585\n",
      "Epoch 90/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6339 - accuracy: 0.6477 - val_loss: 0.6342 - val_accuracy: 0.6585\n",
      "Epoch 91/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.6335 - accuracy: 0.6477 - val_loss: 0.6339 - val_accuracy: 0.6585\n",
      "Epoch 92/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.6332 - accuracy: 0.6477 - val_loss: 0.6337 - val_accuracy: 0.6585\n",
      "Epoch 93/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6328 - accuracy: 0.6477 - val_loss: 0.6335 - val_accuracy: 0.6585\n",
      "Epoch 94/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6324 - accuracy: 0.6477 - val_loss: 0.6332 - val_accuracy: 0.6585\n",
      "Epoch 95/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.6321 - accuracy: 0.6477 - val_loss: 0.6330 - val_accuracy: 0.6585\n",
      "Epoch 96/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6318 - accuracy: 0.6477 - val_loss: 0.6328 - val_accuracy: 0.6585\n",
      "Epoch 97/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6314 - accuracy: 0.6477 - val_loss: 0.6325 - val_accuracy: 0.6585\n",
      "Epoch 98/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6310 - accuracy: 0.6477 - val_loss: 0.6322 - val_accuracy: 0.6585\n",
      "Epoch 99/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.6307 - accuracy: 0.6477 - val_loss: 0.6319 - val_accuracy: 0.6585\n",
      "Epoch 100/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6303 - accuracy: 0.6477 - val_loss: 0.6317 - val_accuracy: 0.6585\n",
      "Epoch 101/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6300 - accuracy: 0.6477 - val_loss: 0.6314 - val_accuracy: 0.6585\n",
      "Epoch 102/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.6297 - accuracy: 0.6477 - val_loss: 0.6312 - val_accuracy: 0.6585\n",
      "Epoch 103/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6292 - accuracy: 0.6477 - val_loss: 0.6309 - val_accuracy: 0.6585\n",
      "Epoch 104/1000\n",
      "491/491 [==============================] - 0s 41us/step - loss: 0.6290 - accuracy: 0.6477 - val_loss: 0.6307 - val_accuracy: 0.6585\n",
      "Epoch 105/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6286 - accuracy: 0.6477 - val_loss: 0.6305 - val_accuracy: 0.6585\n",
      "Epoch 106/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6282 - accuracy: 0.6477 - val_loss: 0.6302 - val_accuracy: 0.6585\n",
      "Epoch 107/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6280 - accuracy: 0.6477 - val_loss: 0.6300 - val_accuracy: 0.6585\n",
      "Epoch 108/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6276 - accuracy: 0.6477 - val_loss: 0.6297 - val_accuracy: 0.6585\n",
      "Epoch 109/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.6271 - accuracy: 0.6477 - val_loss: 0.6295 - val_accuracy: 0.6585\n",
      "Epoch 110/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6270 - accuracy: 0.6477 - val_loss: 0.6292 - val_accuracy: 0.6585\n",
      "Epoch 111/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6264 - accuracy: 0.6477 - val_loss: 0.6290 - val_accuracy: 0.6585\n",
      "Epoch 112/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6261 - accuracy: 0.6477 - val_loss: 0.6287 - val_accuracy: 0.6585\n",
      "Epoch 113/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6256 - accuracy: 0.6477 - val_loss: 0.6285 - val_accuracy: 0.6585\n",
      "Epoch 114/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6253 - accuracy: 0.6477 - val_loss: 0.6282 - val_accuracy: 0.6585\n",
      "Epoch 115/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.6249 - accuracy: 0.6477 - val_loss: 0.6280 - val_accuracy: 0.6585\n",
      "Epoch 116/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.6246 - accuracy: 0.6477 - val_loss: 0.6277 - val_accuracy: 0.6585\n",
      "Epoch 117/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6242 - accuracy: 0.6477 - val_loss: 0.6275 - val_accuracy: 0.6585\n",
      "Epoch 118/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.6238 - accuracy: 0.6477 - val_loss: 0.6272 - val_accuracy: 0.6585\n",
      "Epoch 119/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.6234 - accuracy: 0.6477 - val_loss: 0.6269 - val_accuracy: 0.6585\n",
      "Epoch 120/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6231 - accuracy: 0.6477 - val_loss: 0.6266 - val_accuracy: 0.6585\n",
      "Epoch 121/1000\n",
      "491/491 [==============================] - 0s 78us/step - loss: 0.6227 - accuracy: 0.6477 - val_loss: 0.6264 - val_accuracy: 0.6585\n",
      "Epoch 122/1000\n",
      "491/491 [==============================] - 0s 45us/step - loss: 0.6224 - accuracy: 0.6477 - val_loss: 0.6261 - val_accuracy: 0.6585\n",
      "Epoch 123/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.6220 - accuracy: 0.6497 - val_loss: 0.6258 - val_accuracy: 0.6585\n",
      "Epoch 124/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6216 - accuracy: 0.6497 - val_loss: 0.6255 - val_accuracy: 0.6585\n",
      "Epoch 125/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.6212 - accuracy: 0.6497 - val_loss: 0.6252 - val_accuracy: 0.6585\n",
      "Epoch 126/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6209 - accuracy: 0.6517 - val_loss: 0.6249 - val_accuracy: 0.6585\n",
      "Epoch 127/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.6205 - accuracy: 0.6517 - val_loss: 0.6246 - val_accuracy: 0.6585\n",
      "Epoch 128/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6201 - accuracy: 0.6497 - val_loss: 0.6244 - val_accuracy: 0.6585\n",
      "Epoch 129/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6197 - accuracy: 0.6517 - val_loss: 0.6241 - val_accuracy: 0.6585\n",
      "Epoch 130/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6194 - accuracy: 0.6517 - val_loss: 0.6238 - val_accuracy: 0.6585\n",
      "Epoch 131/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6190 - accuracy: 0.6517 - val_loss: 0.6235 - val_accuracy: 0.6585\n",
      "Epoch 132/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6186 - accuracy: 0.6517 - val_loss: 0.6233 - val_accuracy: 0.6585\n",
      "Epoch 133/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6182 - accuracy: 0.6517 - val_loss: 0.6231 - val_accuracy: 0.6585\n",
      "Epoch 134/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6178 - accuracy: 0.6517 - val_loss: 0.6228 - val_accuracy: 0.6585\n",
      "Epoch 135/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6175 - accuracy: 0.6517 - val_loss: 0.6225 - val_accuracy: 0.6585\n",
      "Epoch 136/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6170 - accuracy: 0.6517 - val_loss: 0.6222 - val_accuracy: 0.6585\n",
      "Epoch 137/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.6168 - accuracy: 0.6517 - val_loss: 0.6219 - val_accuracy: 0.6504\n",
      "Epoch 138/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6164 - accuracy: 0.6517 - val_loss: 0.6216 - val_accuracy: 0.6504\n",
      "Epoch 139/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6159 - accuracy: 0.6517 - val_loss: 0.6213 - val_accuracy: 0.6504\n",
      "Epoch 140/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6156 - accuracy: 0.6517 - val_loss: 0.6210 - val_accuracy: 0.6504\n",
      "Epoch 141/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6151 - accuracy: 0.6538 - val_loss: 0.6207 - val_accuracy: 0.6504\n",
      "Epoch 142/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6148 - accuracy: 0.6538 - val_loss: 0.6204 - val_accuracy: 0.6504\n",
      "Epoch 143/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6145 - accuracy: 0.6538 - val_loss: 0.6201 - val_accuracy: 0.6504\n",
      "Epoch 144/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.6140 - accuracy: 0.6538 - val_loss: 0.6198 - val_accuracy: 0.6504\n",
      "Epoch 145/1000\n",
      "491/491 [==============================] - 0s 17us/step - loss: 0.6137 - accuracy: 0.6538 - val_loss: 0.6195 - val_accuracy: 0.6504\n",
      "Epoch 146/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6132 - accuracy: 0.6538 - val_loss: 0.6192 - val_accuracy: 0.6423\n",
      "Epoch 147/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.6129 - accuracy: 0.6558 - val_loss: 0.6188 - val_accuracy: 0.6423\n",
      "Epoch 148/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.6124 - accuracy: 0.6538 - val_loss: 0.6185 - val_accuracy: 0.6423\n",
      "Epoch 149/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6120 - accuracy: 0.6538 - val_loss: 0.6182 - val_accuracy: 0.6423\n",
      "Epoch 150/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.6116 - accuracy: 0.6538 - val_loss: 0.6179 - val_accuracy: 0.6423\n",
      "Epoch 151/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.6112 - accuracy: 0.6538 - val_loss: 0.6176 - val_accuracy: 0.6423\n",
      "Epoch 152/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6109 - accuracy: 0.6538 - val_loss: 0.6173 - val_accuracy: 0.6423\n",
      "Epoch 153/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6104 - accuracy: 0.6517 - val_loss: 0.6170 - val_accuracy: 0.6423\n",
      "Epoch 154/1000\n",
      "491/491 [==============================] - 0s 34us/step - loss: 0.6101 - accuracy: 0.6538 - val_loss: 0.6167 - val_accuracy: 0.6423\n",
      "Epoch 155/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.6097 - accuracy: 0.6599 - val_loss: 0.6163 - val_accuracy: 0.6423\n",
      "Epoch 156/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6093 - accuracy: 0.6538 - val_loss: 0.6161 - val_accuracy: 0.6504\n",
      "Epoch 157/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.6089 - accuracy: 0.6578 - val_loss: 0.6158 - val_accuracy: 0.6504\n",
      "Epoch 158/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.6084 - accuracy: 0.6578 - val_loss: 0.6154 - val_accuracy: 0.6504\n",
      "Epoch 159/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6080 - accuracy: 0.6599 - val_loss: 0.6151 - val_accuracy: 0.6423\n",
      "Epoch 160/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6077 - accuracy: 0.6578 - val_loss: 0.6148 - val_accuracy: 0.6423\n",
      "Epoch 161/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.6073 - accuracy: 0.6599 - val_loss: 0.6145 - val_accuracy: 0.6423\n",
      "Epoch 162/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6068 - accuracy: 0.6599 - val_loss: 0.6142 - val_accuracy: 0.6504\n",
      "Epoch 163/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.6064 - accuracy: 0.6640 - val_loss: 0.6138 - val_accuracy: 0.6504\n",
      "Epoch 164/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6061 - accuracy: 0.6599 - val_loss: 0.6135 - val_accuracy: 0.6504\n",
      "Epoch 165/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6056 - accuracy: 0.6680 - val_loss: 0.6131 - val_accuracy: 0.6504\n",
      "Epoch 166/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.6052 - accuracy: 0.6599 - val_loss: 0.6128 - val_accuracy: 0.6504\n",
      "Epoch 167/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.6047 - accuracy: 0.6640 - val_loss: 0.6125 - val_accuracy: 0.6504\n",
      "Epoch 168/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.6043 - accuracy: 0.6619 - val_loss: 0.6122 - val_accuracy: 0.6504\n",
      "Epoch 169/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.6039 - accuracy: 0.6701 - val_loss: 0.6118 - val_accuracy: 0.6504\n",
      "Epoch 170/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.6035 - accuracy: 0.6721 - val_loss: 0.6116 - val_accuracy: 0.6423\n",
      "Epoch 171/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6031 - accuracy: 0.6782 - val_loss: 0.6112 - val_accuracy: 0.6423\n",
      "Epoch 172/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.6026 - accuracy: 0.6762 - val_loss: 0.6109 - val_accuracy: 0.6423\n",
      "Epoch 173/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.6024 - accuracy: 0.6782 - val_loss: 0.6106 - val_accuracy: 0.6423\n",
      "Epoch 174/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.6018 - accuracy: 0.6782 - val_loss: 0.6102 - val_accuracy: 0.6423\n",
      "Epoch 175/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.6015 - accuracy: 0.6762 - val_loss: 0.6099 - val_accuracy: 0.6423\n",
      "Epoch 176/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6010 - accuracy: 0.6802 - val_loss: 0.6096 - val_accuracy: 0.6504\n",
      "Epoch 177/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.6007 - accuracy: 0.6823 - val_loss: 0.6093 - val_accuracy: 0.6504\n",
      "Epoch 178/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.6002 - accuracy: 0.6823 - val_loss: 0.6089 - val_accuracy: 0.6504\n",
      "Epoch 179/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.5998 - accuracy: 0.6843 - val_loss: 0.6086 - val_accuracy: 0.6504\n",
      "Epoch 180/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5993 - accuracy: 0.6823 - val_loss: 0.6082 - val_accuracy: 0.6504\n",
      "Epoch 181/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5990 - accuracy: 0.6823 - val_loss: 0.6079 - val_accuracy: 0.6504\n",
      "Epoch 182/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5984 - accuracy: 0.6823 - val_loss: 0.6075 - val_accuracy: 0.6585\n",
      "Epoch 183/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5981 - accuracy: 0.6823 - val_loss: 0.6072 - val_accuracy: 0.6585\n",
      "Epoch 184/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5977 - accuracy: 0.6843 - val_loss: 0.6069 - val_accuracy: 0.6585\n",
      "Epoch 185/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5972 - accuracy: 0.6843 - val_loss: 0.6065 - val_accuracy: 0.6585\n",
      "Epoch 186/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5968 - accuracy: 0.6864 - val_loss: 0.6062 - val_accuracy: 0.6585\n",
      "Epoch 187/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.5964 - accuracy: 0.6864 - val_loss: 0.6058 - val_accuracy: 0.6585\n",
      "Epoch 188/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5959 - accuracy: 0.6864 - val_loss: 0.6055 - val_accuracy: 0.6585\n",
      "Epoch 189/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5956 - accuracy: 0.6884 - val_loss: 0.6052 - val_accuracy: 0.6585\n",
      "Epoch 190/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5950 - accuracy: 0.6864 - val_loss: 0.6048 - val_accuracy: 0.6585\n",
      "Epoch 191/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5947 - accuracy: 0.6945 - val_loss: 0.6045 - val_accuracy: 0.6585\n",
      "Epoch 192/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5943 - accuracy: 0.6884 - val_loss: 0.6042 - val_accuracy: 0.6585\n",
      "Epoch 193/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5939 - accuracy: 0.6925 - val_loss: 0.6039 - val_accuracy: 0.6585\n",
      "Epoch 194/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.5935 - accuracy: 0.6904 - val_loss: 0.6035 - val_accuracy: 0.6585\n",
      "Epoch 195/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.5929 - accuracy: 0.7006 - val_loss: 0.6032 - val_accuracy: 0.6585\n",
      "Epoch 196/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5924 - accuracy: 0.7006 - val_loss: 0.6028 - val_accuracy: 0.6585\n",
      "Epoch 197/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5921 - accuracy: 0.7026 - val_loss: 0.6025 - val_accuracy: 0.6585\n",
      "Epoch 198/1000\n",
      "491/491 [==============================] - 0s 34us/step - loss: 0.5916 - accuracy: 0.7006 - val_loss: 0.6021 - val_accuracy: 0.6585\n",
      "Epoch 199/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.5913 - accuracy: 0.7026 - val_loss: 0.6018 - val_accuracy: 0.6585\n",
      "Epoch 200/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5906 - accuracy: 0.7026 - val_loss: 0.6014 - val_accuracy: 0.6585\n",
      "Epoch 201/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5903 - accuracy: 0.7006 - val_loss: 0.6011 - val_accuracy: 0.6585\n",
      "Epoch 202/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5900 - accuracy: 0.7006 - val_loss: 0.6008 - val_accuracy: 0.6585\n",
      "Epoch 203/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5894 - accuracy: 0.7026 - val_loss: 0.6004 - val_accuracy: 0.6585\n",
      "Epoch 204/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5890 - accuracy: 0.7026 - val_loss: 0.6001 - val_accuracy: 0.6504\n",
      "Epoch 205/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5886 - accuracy: 0.7026 - val_loss: 0.5997 - val_accuracy: 0.6504\n",
      "Epoch 206/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.5882 - accuracy: 0.7026 - val_loss: 0.5994 - val_accuracy: 0.6504\n",
      "Epoch 207/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5877 - accuracy: 0.7067 - val_loss: 0.5991 - val_accuracy: 0.6504\n",
      "Epoch 208/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5872 - accuracy: 0.7026 - val_loss: 0.5987 - val_accuracy: 0.6504\n",
      "Epoch 209/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5867 - accuracy: 0.7026 - val_loss: 0.5983 - val_accuracy: 0.6585\n",
      "Epoch 210/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5864 - accuracy: 0.7047 - val_loss: 0.5980 - val_accuracy: 0.6585\n",
      "Epoch 211/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.5858 - accuracy: 0.7047 - val_loss: 0.5977 - val_accuracy: 0.6585\n",
      "Epoch 212/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.5854 - accuracy: 0.7026 - val_loss: 0.5973 - val_accuracy: 0.6585\n",
      "Epoch 213/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.5850 - accuracy: 0.7067 - val_loss: 0.5970 - val_accuracy: 0.6667\n",
      "Epoch 214/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.5846 - accuracy: 0.7088 - val_loss: 0.5967 - val_accuracy: 0.6748\n",
      "Epoch 215/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.5841 - accuracy: 0.7088 - val_loss: 0.5963 - val_accuracy: 0.6829\n",
      "Epoch 216/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5838 - accuracy: 0.7067 - val_loss: 0.5959 - val_accuracy: 0.6829\n",
      "Epoch 217/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.5833 - accuracy: 0.7067 - val_loss: 0.5956 - val_accuracy: 0.6829\n",
      "Epoch 218/1000\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.80 - 0s 29us/step - loss: 0.5829 - accuracy: 0.7088 - val_loss: 0.5952 - val_accuracy: 0.6829\n",
      "Epoch 219/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5822 - accuracy: 0.7108 - val_loss: 0.5949 - val_accuracy: 0.6829\n",
      "Epoch 220/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5819 - accuracy: 0.7088 - val_loss: 0.5945 - val_accuracy: 0.6829\n",
      "Epoch 221/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5814 - accuracy: 0.7088 - val_loss: 0.5942 - val_accuracy: 0.6829\n",
      "Epoch 222/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5810 - accuracy: 0.7047 - val_loss: 0.5938 - val_accuracy: 0.6829\n",
      "Epoch 223/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5806 - accuracy: 0.7067 - val_loss: 0.5934 - val_accuracy: 0.6829\n",
      "Epoch 224/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.5801 - accuracy: 0.7047 - val_loss: 0.5931 - val_accuracy: 0.6829\n",
      "Epoch 225/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5798 - accuracy: 0.7067 - val_loss: 0.5927 - val_accuracy: 0.6829\n",
      "Epoch 226/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5791 - accuracy: 0.7047 - val_loss: 0.5924 - val_accuracy: 0.6829\n",
      "Epoch 227/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.5787 - accuracy: 0.7067 - val_loss: 0.5921 - val_accuracy: 0.6829\n",
      "Epoch 228/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5783 - accuracy: 0.7067 - val_loss: 0.5917 - val_accuracy: 0.6829\n",
      "Epoch 229/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5779 - accuracy: 0.7047 - val_loss: 0.5914 - val_accuracy: 0.6829\n",
      "Epoch 230/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.5774 - accuracy: 0.7067 - val_loss: 0.5910 - val_accuracy: 0.6829\n",
      "Epoch 231/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.5769 - accuracy: 0.7067 - val_loss: 0.5907 - val_accuracy: 0.6829\n",
      "Epoch 232/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.5766 - accuracy: 0.7067 - val_loss: 0.5903 - val_accuracy: 0.6829\n",
      "Epoch 233/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.5761 - accuracy: 0.7047 - val_loss: 0.5900 - val_accuracy: 0.6829\n",
      "Epoch 234/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5756 - accuracy: 0.7067 - val_loss: 0.5897 - val_accuracy: 0.6748\n",
      "Epoch 235/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5751 - accuracy: 0.7047 - val_loss: 0.5893 - val_accuracy: 0.6748\n",
      "Epoch 236/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5747 - accuracy: 0.7067 - val_loss: 0.5890 - val_accuracy: 0.6748\n",
      "Epoch 237/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5743 - accuracy: 0.7047 - val_loss: 0.5887 - val_accuracy: 0.6748\n",
      "Epoch 238/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5738 - accuracy: 0.7047 - val_loss: 0.5883 - val_accuracy: 0.6748\n",
      "Epoch 239/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5735 - accuracy: 0.7067 - val_loss: 0.5879 - val_accuracy: 0.6748\n",
      "Epoch 240/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5730 - accuracy: 0.7067 - val_loss: 0.5876 - val_accuracy: 0.6829\n",
      "Epoch 241/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5725 - accuracy: 0.7067 - val_loss: 0.5872 - val_accuracy: 0.6829\n",
      "Epoch 242/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5720 - accuracy: 0.7067 - val_loss: 0.5869 - val_accuracy: 0.6829\n",
      "Epoch 243/1000\n",
      "491/491 [==============================] - 0s 17us/step - loss: 0.5717 - accuracy: 0.7067 - val_loss: 0.5866 - val_accuracy: 0.6829\n",
      "Epoch 244/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.5711 - accuracy: 0.7047 - val_loss: 0.5862 - val_accuracy: 0.6748\n",
      "Epoch 245/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5706 - accuracy: 0.7026 - val_loss: 0.5859 - val_accuracy: 0.6748\n",
      "Epoch 246/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5703 - accuracy: 0.7088 - val_loss: 0.5856 - val_accuracy: 0.6748\n",
      "Epoch 247/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5698 - accuracy: 0.7088 - val_loss: 0.5853 - val_accuracy: 0.6911\n",
      "Epoch 248/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5695 - accuracy: 0.7067 - val_loss: 0.5850 - val_accuracy: 0.6992\n",
      "Epoch 249/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5690 - accuracy: 0.7067 - val_loss: 0.5846 - val_accuracy: 0.6911\n",
      "Epoch 250/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5685 - accuracy: 0.7067 - val_loss: 0.5843 - val_accuracy: 0.6992\n",
      "Epoch 251/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5680 - accuracy: 0.7067 - val_loss: 0.5840 - val_accuracy: 0.6992\n",
      "Epoch 252/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5676 - accuracy: 0.7067 - val_loss: 0.5836 - val_accuracy: 0.6911\n",
      "Epoch 253/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5673 - accuracy: 0.7047 - val_loss: 0.5833 - val_accuracy: 0.6911\n",
      "Epoch 254/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5669 - accuracy: 0.7067 - val_loss: 0.5830 - val_accuracy: 0.6911\n",
      "Epoch 255/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5663 - accuracy: 0.7047 - val_loss: 0.5826 - val_accuracy: 0.6911\n",
      "Epoch 256/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5658 - accuracy: 0.7067 - val_loss: 0.5823 - val_accuracy: 0.6911\n",
      "Epoch 257/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5657 - accuracy: 0.7088 - val_loss: 0.5820 - val_accuracy: 0.6911\n",
      "Epoch 258/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5649 - accuracy: 0.7047 - val_loss: 0.5816 - val_accuracy: 0.6911\n",
      "Epoch 259/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5645 - accuracy: 0.7047 - val_loss: 0.5813 - val_accuracy: 0.6911\n",
      "Epoch 260/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5642 - accuracy: 0.7067 - val_loss: 0.5810 - val_accuracy: 0.6829\n",
      "Epoch 261/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.5636 - accuracy: 0.7108 - val_loss: 0.5806 - val_accuracy: 0.6911\n",
      "Epoch 262/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5634 - accuracy: 0.7108 - val_loss: 0.5803 - val_accuracy: 0.6911\n",
      "Epoch 263/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5628 - accuracy: 0.7088 - val_loss: 0.5800 - val_accuracy: 0.6911\n",
      "Epoch 264/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5625 - accuracy: 0.7149 - val_loss: 0.5796 - val_accuracy: 0.6911\n",
      "Epoch 265/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5618 - accuracy: 0.7088 - val_loss: 0.5793 - val_accuracy: 0.6911\n",
      "Epoch 266/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.5615 - accuracy: 0.7047 - val_loss: 0.5790 - val_accuracy: 0.6829\n",
      "Epoch 267/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5611 - accuracy: 0.7108 - val_loss: 0.5787 - val_accuracy: 0.6829\n",
      "Epoch 268/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5606 - accuracy: 0.7128 - val_loss: 0.5784 - val_accuracy: 0.6829\n",
      "Epoch 269/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5602 - accuracy: 0.7128 - val_loss: 0.5781 - val_accuracy: 0.6829\n",
      "Epoch 270/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5600 - accuracy: 0.7088 - val_loss: 0.5778 - val_accuracy: 0.6829\n",
      "Epoch 271/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5595 - accuracy: 0.7108 - val_loss: 0.5775 - val_accuracy: 0.6829\n",
      "Epoch 272/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5590 - accuracy: 0.7149 - val_loss: 0.5772 - val_accuracy: 0.6829\n",
      "Epoch 273/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5586 - accuracy: 0.7108 - val_loss: 0.5768 - val_accuracy: 0.6829\n",
      "Epoch 274/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5580 - accuracy: 0.7108 - val_loss: 0.5765 - val_accuracy: 0.6829\n",
      "Epoch 275/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5579 - accuracy: 0.7128 - val_loss: 0.5762 - val_accuracy: 0.6829\n",
      "Epoch 276/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5574 - accuracy: 0.7149 - val_loss: 0.5760 - val_accuracy: 0.6829\n",
      "Epoch 277/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5569 - accuracy: 0.7108 - val_loss: 0.5757 - val_accuracy: 0.6829\n",
      "Epoch 278/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5565 - accuracy: 0.7067 - val_loss: 0.5754 - val_accuracy: 0.6829\n",
      "Epoch 279/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5559 - accuracy: 0.7108 - val_loss: 0.5750 - val_accuracy: 0.6829\n",
      "Epoch 280/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5555 - accuracy: 0.7047 - val_loss: 0.5747 - val_accuracy: 0.6829\n",
      "Epoch 281/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5552 - accuracy: 0.7108 - val_loss: 0.5743 - val_accuracy: 0.6829\n",
      "Epoch 282/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5546 - accuracy: 0.7067 - val_loss: 0.5740 - val_accuracy: 0.6829\n",
      "Epoch 283/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5543 - accuracy: 0.7128 - val_loss: 0.5737 - val_accuracy: 0.6829\n",
      "Epoch 284/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5541 - accuracy: 0.7149 - val_loss: 0.5735 - val_accuracy: 0.6911\n",
      "Epoch 285/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5538 - accuracy: 0.7067 - val_loss: 0.5732 - val_accuracy: 0.6992\n",
      "Epoch 286/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5530 - accuracy: 0.7067 - val_loss: 0.5729 - val_accuracy: 0.6911\n",
      "Epoch 287/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5527 - accuracy: 0.7067 - val_loss: 0.5726 - val_accuracy: 0.6992\n",
      "Epoch 288/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5524 - accuracy: 0.7108 - val_loss: 0.5723 - val_accuracy: 0.6992\n",
      "Epoch 289/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5519 - accuracy: 0.7108 - val_loss: 0.5720 - val_accuracy: 0.6992\n",
      "Epoch 290/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5514 - accuracy: 0.7067 - val_loss: 0.5717 - val_accuracy: 0.6992\n",
      "Epoch 291/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5509 - accuracy: 0.7108 - val_loss: 0.5714 - val_accuracy: 0.6992\n",
      "Epoch 292/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5505 - accuracy: 0.7088 - val_loss: 0.5711 - val_accuracy: 0.6992\n",
      "Epoch 293/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5502 - accuracy: 0.7067 - val_loss: 0.5707 - val_accuracy: 0.6992\n",
      "Epoch 294/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5497 - accuracy: 0.7088 - val_loss: 0.5704 - val_accuracy: 0.6992\n",
      "Epoch 295/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.5494 - accuracy: 0.7128 - val_loss: 0.5701 - val_accuracy: 0.6992\n",
      "Epoch 296/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5490 - accuracy: 0.7128 - val_loss: 0.5699 - val_accuracy: 0.6992\n",
      "Epoch 297/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5485 - accuracy: 0.7128 - val_loss: 0.5696 - val_accuracy: 0.6992\n",
      "Epoch 298/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5484 - accuracy: 0.7149 - val_loss: 0.5693 - val_accuracy: 0.6992\n",
      "Epoch 299/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5478 - accuracy: 0.7149 - val_loss: 0.5690 - val_accuracy: 0.6992\n",
      "Epoch 300/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5473 - accuracy: 0.7128 - val_loss: 0.5687 - val_accuracy: 0.6992\n",
      "Epoch 301/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5475 - accuracy: 0.7169 - val_loss: 0.5684 - val_accuracy: 0.6992\n",
      "Epoch 302/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5466 - accuracy: 0.7128 - val_loss: 0.5681 - val_accuracy: 0.6992\n",
      "Epoch 303/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5461 - accuracy: 0.7149 - val_loss: 0.5679 - val_accuracy: 0.6992\n",
      "Epoch 304/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5457 - accuracy: 0.7128 - val_loss: 0.5676 - val_accuracy: 0.6992\n",
      "Epoch 305/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5452 - accuracy: 0.7189 - val_loss: 0.5673 - val_accuracy: 0.6992\n",
      "Epoch 306/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5450 - accuracy: 0.7189 - val_loss: 0.5670 - val_accuracy: 0.6992\n",
      "Epoch 307/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5446 - accuracy: 0.7169 - val_loss: 0.5668 - val_accuracy: 0.6992\n",
      "Epoch 308/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5441 - accuracy: 0.7189 - val_loss: 0.5665 - val_accuracy: 0.6992\n",
      "Epoch 309/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5439 - accuracy: 0.7189 - val_loss: 0.5662 - val_accuracy: 0.6992\n",
      "Epoch 310/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5435 - accuracy: 0.7230 - val_loss: 0.5659 - val_accuracy: 0.6992\n",
      "Epoch 311/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5432 - accuracy: 0.7189 - val_loss: 0.5656 - val_accuracy: 0.6992\n",
      "Epoch 312/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5426 - accuracy: 0.7210 - val_loss: 0.5654 - val_accuracy: 0.6992\n",
      "Epoch 313/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5420 - accuracy: 0.7210 - val_loss: 0.5651 - val_accuracy: 0.6992\n",
      "Epoch 314/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5420 - accuracy: 0.7251 - val_loss: 0.5649 - val_accuracy: 0.6992\n",
      "Epoch 315/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5413 - accuracy: 0.7210 - val_loss: 0.5646 - val_accuracy: 0.6992\n",
      "Epoch 316/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5412 - accuracy: 0.7210 - val_loss: 0.5643 - val_accuracy: 0.6992\n",
      "Epoch 317/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5406 - accuracy: 0.7230 - val_loss: 0.5641 - val_accuracy: 0.6992\n",
      "Epoch 318/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5403 - accuracy: 0.7230 - val_loss: 0.5638 - val_accuracy: 0.6992\n",
      "Epoch 319/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5399 - accuracy: 0.7210 - val_loss: 0.5635 - val_accuracy: 0.6992\n",
      "Epoch 320/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5395 - accuracy: 0.7189 - val_loss: 0.5632 - val_accuracy: 0.6992\n",
      "Epoch 321/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5393 - accuracy: 0.7210 - val_loss: 0.5630 - val_accuracy: 0.6992\n",
      "Epoch 322/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5390 - accuracy: 0.7230 - val_loss: 0.5627 - val_accuracy: 0.6992\n",
      "Epoch 323/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5385 - accuracy: 0.7230 - val_loss: 0.5625 - val_accuracy: 0.6992\n",
      "Epoch 324/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5381 - accuracy: 0.7189 - val_loss: 0.5622 - val_accuracy: 0.6992\n",
      "Epoch 325/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5378 - accuracy: 0.7230 - val_loss: 0.5619 - val_accuracy: 0.6992\n",
      "Epoch 326/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5373 - accuracy: 0.7251 - val_loss: 0.5617 - val_accuracy: 0.6992\n",
      "Epoch 327/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5371 - accuracy: 0.7251 - val_loss: 0.5614 - val_accuracy: 0.6992\n",
      "Epoch 328/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5368 - accuracy: 0.7230 - val_loss: 0.5612 - val_accuracy: 0.6992\n",
      "Epoch 329/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5366 - accuracy: 0.7230 - val_loss: 0.5609 - val_accuracy: 0.6992\n",
      "Epoch 330/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5357 - accuracy: 0.7230 - val_loss: 0.5607 - val_accuracy: 0.6992\n",
      "Epoch 331/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5353 - accuracy: 0.7230 - val_loss: 0.5604 - val_accuracy: 0.6992\n",
      "Epoch 332/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5350 - accuracy: 0.7230 - val_loss: 0.5602 - val_accuracy: 0.6992\n",
      "Epoch 333/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5346 - accuracy: 0.7189 - val_loss: 0.5600 - val_accuracy: 0.6992\n",
      "Epoch 334/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5342 - accuracy: 0.7230 - val_loss: 0.5597 - val_accuracy: 0.6992\n",
      "Epoch 335/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5337 - accuracy: 0.7210 - val_loss: 0.5595 - val_accuracy: 0.6992\n",
      "Epoch 336/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5335 - accuracy: 0.7169 - val_loss: 0.5592 - val_accuracy: 0.6992\n",
      "Epoch 337/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.5332 - accuracy: 0.7189 - val_loss: 0.5590 - val_accuracy: 0.6992\n",
      "Epoch 338/1000\n",
      "491/491 [==============================] - 0s 36us/step - loss: 0.5329 - accuracy: 0.7189 - val_loss: 0.5587 - val_accuracy: 0.6992\n",
      "Epoch 339/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5323 - accuracy: 0.7210 - val_loss: 0.5585 - val_accuracy: 0.6992\n",
      "Epoch 340/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.5321 - accuracy: 0.7210 - val_loss: 0.5583 - val_accuracy: 0.6992\n",
      "Epoch 341/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.5315 - accuracy: 0.7189 - val_loss: 0.5581 - val_accuracy: 0.6992\n",
      "Epoch 342/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5312 - accuracy: 0.7210 - val_loss: 0.5578 - val_accuracy: 0.6992\n",
      "Epoch 343/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5312 - accuracy: 0.7189 - val_loss: 0.5576 - val_accuracy: 0.6992\n",
      "Epoch 344/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5307 - accuracy: 0.7189 - val_loss: 0.5574 - val_accuracy: 0.6992\n",
      "Epoch 345/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5302 - accuracy: 0.7189 - val_loss: 0.5571 - val_accuracy: 0.6992\n",
      "Epoch 346/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5302 - accuracy: 0.7230 - val_loss: 0.5569 - val_accuracy: 0.6992\n",
      "Epoch 347/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5298 - accuracy: 0.7230 - val_loss: 0.5567 - val_accuracy: 0.6992\n",
      "Epoch 348/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5293 - accuracy: 0.7210 - val_loss: 0.5565 - val_accuracy: 0.7073\n",
      "Epoch 349/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5287 - accuracy: 0.7230 - val_loss: 0.5562 - val_accuracy: 0.6992\n",
      "Epoch 350/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5285 - accuracy: 0.7230 - val_loss: 0.5558 - val_accuracy: 0.6992\n",
      "Epoch 351/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5279 - accuracy: 0.7230 - val_loss: 0.5556 - val_accuracy: 0.6992\n",
      "Epoch 352/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5277 - accuracy: 0.7210 - val_loss: 0.5554 - val_accuracy: 0.6992\n",
      "Epoch 353/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5270 - accuracy: 0.7251 - val_loss: 0.5552 - val_accuracy: 0.7073\n",
      "Epoch 354/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5266 - accuracy: 0.7230 - val_loss: 0.5549 - val_accuracy: 0.6992\n",
      "Epoch 355/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5264 - accuracy: 0.7251 - val_loss: 0.5546 - val_accuracy: 0.6992\n",
      "Epoch 356/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5262 - accuracy: 0.7230 - val_loss: 0.5543 - val_accuracy: 0.6992\n",
      "Epoch 357/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5261 - accuracy: 0.7230 - val_loss: 0.5541 - val_accuracy: 0.6992\n",
      "Epoch 358/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5253 - accuracy: 0.7210 - val_loss: 0.5539 - val_accuracy: 0.7073\n",
      "Epoch 359/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5256 - accuracy: 0.7230 - val_loss: 0.5536 - val_accuracy: 0.6992\n",
      "Epoch 360/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5244 - accuracy: 0.7210 - val_loss: 0.5533 - val_accuracy: 0.6992\n",
      "Epoch 361/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.5249 - accuracy: 0.7230 - val_loss: 0.5531 - val_accuracy: 0.6992\n",
      "Epoch 362/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5238 - accuracy: 0.7230 - val_loss: 0.5527 - val_accuracy: 0.6911\n",
      "Epoch 363/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5237 - accuracy: 0.7251 - val_loss: 0.5525 - val_accuracy: 0.6992\n",
      "Epoch 364/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5230 - accuracy: 0.7230 - val_loss: 0.5521 - val_accuracy: 0.6911\n",
      "Epoch 365/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5225 - accuracy: 0.7230 - val_loss: 0.5519 - val_accuracy: 0.7073\n",
      "Epoch 366/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5221 - accuracy: 0.7230 - val_loss: 0.5516 - val_accuracy: 0.7073\n",
      "Epoch 367/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5220 - accuracy: 0.7210 - val_loss: 0.5513 - val_accuracy: 0.7073\n",
      "Epoch 368/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5213 - accuracy: 0.7251 - val_loss: 0.5509 - val_accuracy: 0.6992\n",
      "Epoch 369/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.5209 - accuracy: 0.7251 - val_loss: 0.5507 - val_accuracy: 0.6992\n",
      "Epoch 370/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5205 - accuracy: 0.7230 - val_loss: 0.5504 - val_accuracy: 0.6992\n",
      "Epoch 371/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.5203 - accuracy: 0.7251 - val_loss: 0.5501 - val_accuracy: 0.6911\n",
      "Epoch 372/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5198 - accuracy: 0.7251 - val_loss: 0.5498 - val_accuracy: 0.6911\n",
      "Epoch 373/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5194 - accuracy: 0.7251 - val_loss: 0.5496 - val_accuracy: 0.6992\n",
      "Epoch 374/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5192 - accuracy: 0.7251 - val_loss: 0.5496 - val_accuracy: 0.7236\n",
      "Epoch 375/1000\n",
      "491/491 [==============================] - 0s 87us/step - loss: 0.5187 - accuracy: 0.7251 - val_loss: 0.5493 - val_accuracy: 0.7236\n",
      "Epoch 376/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.5188 - accuracy: 0.7271 - val_loss: 0.5490 - val_accuracy: 0.7073\n",
      "Epoch 377/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5183 - accuracy: 0.7251 - val_loss: 0.5487 - val_accuracy: 0.7073\n",
      "Epoch 378/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5175 - accuracy: 0.7251 - val_loss: 0.5486 - val_accuracy: 0.7236\n",
      "Epoch 379/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5173 - accuracy: 0.7291 - val_loss: 0.5483 - val_accuracy: 0.7073\n",
      "Epoch 380/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5169 - accuracy: 0.7251 - val_loss: 0.5481 - val_accuracy: 0.7154\n",
      "Epoch 381/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5167 - accuracy: 0.7312 - val_loss: 0.5479 - val_accuracy: 0.7154\n",
      "Epoch 382/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.5162 - accuracy: 0.7291 - val_loss: 0.5477 - val_accuracy: 0.7154\n",
      "Epoch 383/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5161 - accuracy: 0.7312 - val_loss: 0.5474 - val_accuracy: 0.7073\n",
      "Epoch 384/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.5159 - accuracy: 0.7291 - val_loss: 0.5472 - val_accuracy: 0.6992\n",
      "Epoch 385/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5157 - accuracy: 0.7312 - val_loss: 0.5470 - val_accuracy: 0.7154\n",
      "Epoch 386/1000\n",
      "491/491 [==============================] - 0s 17us/step - loss: 0.5153 - accuracy: 0.7271 - val_loss: 0.5468 - val_accuracy: 0.7154\n",
      "Epoch 387/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.5151 - accuracy: 0.7312 - val_loss: 0.5470 - val_accuracy: 0.7236\n",
      "Epoch 388/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5150 - accuracy: 0.7312 - val_loss: 0.5466 - val_accuracy: 0.7236\n",
      "Epoch 389/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.5141 - accuracy: 0.7373 - val_loss: 0.5463 - val_accuracy: 0.7154\n",
      "Epoch 390/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5138 - accuracy: 0.7291 - val_loss: 0.5461 - val_accuracy: 0.7154\n",
      "Epoch 391/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5137 - accuracy: 0.7352 - val_loss: 0.5459 - val_accuracy: 0.7154\n",
      "Epoch 392/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5132 - accuracy: 0.7332 - val_loss: 0.5458 - val_accuracy: 0.7236\n",
      "Epoch 393/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5130 - accuracy: 0.7312 - val_loss: 0.5456 - val_accuracy: 0.7236\n",
      "Epoch 394/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5124 - accuracy: 0.7312 - val_loss: 0.5453 - val_accuracy: 0.7154\n",
      "Epoch 395/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5122 - accuracy: 0.7332 - val_loss: 0.5452 - val_accuracy: 0.7154\n",
      "Epoch 396/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.5124 - accuracy: 0.7332 - val_loss: 0.5450 - val_accuracy: 0.7154\n",
      "Epoch 397/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5117 - accuracy: 0.7332 - val_loss: 0.5448 - val_accuracy: 0.7154\n",
      "Epoch 398/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5114 - accuracy: 0.7312 - val_loss: 0.5446 - val_accuracy: 0.7154\n",
      "Epoch 399/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5111 - accuracy: 0.7312 - val_loss: 0.5444 - val_accuracy: 0.7073\n",
      "Epoch 400/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5107 - accuracy: 0.7312 - val_loss: 0.5443 - val_accuracy: 0.7073\n",
      "Epoch 401/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5105 - accuracy: 0.7352 - val_loss: 0.5441 - val_accuracy: 0.6992\n",
      "Epoch 402/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.5104 - accuracy: 0.7312 - val_loss: 0.5439 - val_accuracy: 0.6992\n",
      "Epoch 403/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5103 - accuracy: 0.7291 - val_loss: 0.5438 - val_accuracy: 0.6992\n",
      "Epoch 404/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.5099 - accuracy: 0.7312 - val_loss: 0.5436 - val_accuracy: 0.6992\n",
      "Epoch 405/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5095 - accuracy: 0.7251 - val_loss: 0.5435 - val_accuracy: 0.7154\n",
      "Epoch 406/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5090 - accuracy: 0.7352 - val_loss: 0.5434 - val_accuracy: 0.7236\n",
      "Epoch 407/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5086 - accuracy: 0.7312 - val_loss: 0.5432 - val_accuracy: 0.7154\n",
      "Epoch 408/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5086 - accuracy: 0.7352 - val_loss: 0.5430 - val_accuracy: 0.7154\n",
      "Epoch 409/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5089 - accuracy: 0.7312 - val_loss: 0.5429 - val_accuracy: 0.7154\n",
      "Epoch 410/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5077 - accuracy: 0.7332 - val_loss: 0.5427 - val_accuracy: 0.7154\n",
      "Epoch 411/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.5076 - accuracy: 0.7332 - val_loss: 0.5425 - val_accuracy: 0.7154\n",
      "Epoch 412/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.5077 - accuracy: 0.7291 - val_loss: 0.5423 - val_accuracy: 0.6992\n",
      "Epoch 413/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5070 - accuracy: 0.7332 - val_loss: 0.5422 - val_accuracy: 0.7154\n",
      "Epoch 414/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.5068 - accuracy: 0.7312 - val_loss: 0.5421 - val_accuracy: 0.7154\n",
      "Epoch 415/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.5069 - accuracy: 0.7332 - val_loss: 0.5419 - val_accuracy: 0.6992\n",
      "Epoch 416/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5062 - accuracy: 0.7332 - val_loss: 0.5417 - val_accuracy: 0.7154\n",
      "Epoch 417/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5059 - accuracy: 0.7352 - val_loss: 0.5415 - val_accuracy: 0.7073\n",
      "Epoch 418/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5056 - accuracy: 0.7352 - val_loss: 0.5414 - val_accuracy: 0.7154\n",
      "Epoch 419/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5053 - accuracy: 0.7332 - val_loss: 0.5412 - val_accuracy: 0.7154\n",
      "Epoch 420/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5053 - accuracy: 0.7291 - val_loss: 0.5413 - val_accuracy: 0.7236\n",
      "Epoch 421/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5048 - accuracy: 0.7332 - val_loss: 0.5411 - val_accuracy: 0.7236\n",
      "Epoch 422/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.5049 - accuracy: 0.7291 - val_loss: 0.5409 - val_accuracy: 0.7236\n",
      "Epoch 423/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5042 - accuracy: 0.7312 - val_loss: 0.5407 - val_accuracy: 0.7236\n",
      "Epoch 424/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5039 - accuracy: 0.7271 - val_loss: 0.5405 - val_accuracy: 0.7236\n",
      "Epoch 425/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5036 - accuracy: 0.7332 - val_loss: 0.5404 - val_accuracy: 0.7236\n",
      "Epoch 426/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5034 - accuracy: 0.7352 - val_loss: 0.5403 - val_accuracy: 0.7236\n",
      "Epoch 427/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5029 - accuracy: 0.7373 - val_loss: 0.5402 - val_accuracy: 0.7236\n",
      "Epoch 428/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5029 - accuracy: 0.7393 - val_loss: 0.5400 - val_accuracy: 0.7236\n",
      "Epoch 429/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5028 - accuracy: 0.7373 - val_loss: 0.5401 - val_accuracy: 0.7236\n",
      "Epoch 430/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5026 - accuracy: 0.7434 - val_loss: 0.5397 - val_accuracy: 0.7236\n",
      "Epoch 431/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.5021 - accuracy: 0.7291 - val_loss: 0.5395 - val_accuracy: 0.7236\n",
      "Epoch 432/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.5021 - accuracy: 0.7373 - val_loss: 0.5395 - val_accuracy: 0.7236\n",
      "Epoch 433/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.5016 - accuracy: 0.7413 - val_loss: 0.5393 - val_accuracy: 0.7317\n",
      "Epoch 434/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5017 - accuracy: 0.7413 - val_loss: 0.5392 - val_accuracy: 0.7317\n",
      "Epoch 435/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.5010 - accuracy: 0.7373 - val_loss: 0.5390 - val_accuracy: 0.7317\n",
      "Epoch 436/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.5010 - accuracy: 0.7393 - val_loss: 0.5390 - val_accuracy: 0.7236\n",
      "Epoch 437/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.5008 - accuracy: 0.7454 - val_loss: 0.5388 - val_accuracy: 0.7398\n",
      "Epoch 438/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.5003 - accuracy: 0.7332 - val_loss: 0.5387 - val_accuracy: 0.7236\n",
      "Epoch 439/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.5003 - accuracy: 0.7373 - val_loss: 0.5385 - val_accuracy: 0.7236\n",
      "Epoch 440/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4998 - accuracy: 0.7434 - val_loss: 0.5384 - val_accuracy: 0.7398\n",
      "Epoch 441/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.4994 - accuracy: 0.7413 - val_loss: 0.5383 - val_accuracy: 0.7317\n",
      "Epoch 442/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4991 - accuracy: 0.7413 - val_loss: 0.5382 - val_accuracy: 0.7317\n",
      "Epoch 443/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4991 - accuracy: 0.7475 - val_loss: 0.5381 - val_accuracy: 0.7317\n",
      "Epoch 444/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4988 - accuracy: 0.7393 - val_loss: 0.5380 - val_accuracy: 0.7317\n",
      "Epoch 445/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4987 - accuracy: 0.7413 - val_loss: 0.5378 - val_accuracy: 0.7317\n",
      "Epoch 446/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4984 - accuracy: 0.7434 - val_loss: 0.5378 - val_accuracy: 0.7317\n",
      "Epoch 447/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4981 - accuracy: 0.7454 - val_loss: 0.5377 - val_accuracy: 0.7236\n",
      "Epoch 448/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4978 - accuracy: 0.7454 - val_loss: 0.5377 - val_accuracy: 0.7317\n",
      "Epoch 449/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4983 - accuracy: 0.7454 - val_loss: 0.5375 - val_accuracy: 0.7317\n",
      "Epoch 450/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4973 - accuracy: 0.7475 - val_loss: 0.5374 - val_accuracy: 0.7317\n",
      "Epoch 451/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4971 - accuracy: 0.7434 - val_loss: 0.5373 - val_accuracy: 0.7317\n",
      "Epoch 452/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4978 - accuracy: 0.7495 - val_loss: 0.5371 - val_accuracy: 0.7317\n",
      "Epoch 453/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4974 - accuracy: 0.7475 - val_loss: 0.5370 - val_accuracy: 0.7317\n",
      "Epoch 454/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4964 - accuracy: 0.7495 - val_loss: 0.5370 - val_accuracy: 0.7398\n",
      "Epoch 455/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4963 - accuracy: 0.7515 - val_loss: 0.5368 - val_accuracy: 0.7398\n",
      "Epoch 456/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4963 - accuracy: 0.7495 - val_loss: 0.5367 - val_accuracy: 0.7317\n",
      "Epoch 457/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4955 - accuracy: 0.7515 - val_loss: 0.5366 - val_accuracy: 0.7317\n",
      "Epoch 458/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4956 - accuracy: 0.7495 - val_loss: 0.5365 - val_accuracy: 0.7317\n",
      "Epoch 459/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4953 - accuracy: 0.7495 - val_loss: 0.5364 - val_accuracy: 0.7317\n",
      "Epoch 460/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4949 - accuracy: 0.7536 - val_loss: 0.5363 - val_accuracy: 0.7398\n",
      "Epoch 461/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4946 - accuracy: 0.7515 - val_loss: 0.5362 - val_accuracy: 0.7317\n",
      "Epoch 462/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4944 - accuracy: 0.7536 - val_loss: 0.5361 - val_accuracy: 0.7398\n",
      "Epoch 463/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4944 - accuracy: 0.7495 - val_loss: 0.5360 - val_accuracy: 0.7317\n",
      "Epoch 464/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4939 - accuracy: 0.7515 - val_loss: 0.5360 - val_accuracy: 0.7398\n",
      "Epoch 465/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4940 - accuracy: 0.7475 - val_loss: 0.5358 - val_accuracy: 0.7398\n",
      "Epoch 466/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4935 - accuracy: 0.7515 - val_loss: 0.5358 - val_accuracy: 0.7398\n",
      "Epoch 467/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4933 - accuracy: 0.7536 - val_loss: 0.5358 - val_accuracy: 0.7398\n",
      "Epoch 468/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4930 - accuracy: 0.7515 - val_loss: 0.5355 - val_accuracy: 0.7317\n",
      "Epoch 469/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4929 - accuracy: 0.7536 - val_loss: 0.5355 - val_accuracy: 0.7398\n",
      "Epoch 470/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4925 - accuracy: 0.7556 - val_loss: 0.5354 - val_accuracy: 0.7398\n",
      "Epoch 471/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4931 - accuracy: 0.7515 - val_loss: 0.5354 - val_accuracy: 0.7398\n",
      "Epoch 472/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4923 - accuracy: 0.7536 - val_loss: 0.5353 - val_accuracy: 0.7398\n",
      "Epoch 473/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4923 - accuracy: 0.7556 - val_loss: 0.5352 - val_accuracy: 0.7398\n",
      "Epoch 474/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4916 - accuracy: 0.7556 - val_loss: 0.5351 - val_accuracy: 0.7398\n",
      "Epoch 475/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4921 - accuracy: 0.7556 - val_loss: 0.5350 - val_accuracy: 0.7398\n",
      "Epoch 476/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4913 - accuracy: 0.7536 - val_loss: 0.5349 - val_accuracy: 0.7317\n",
      "Epoch 477/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4912 - accuracy: 0.7536 - val_loss: 0.5348 - val_accuracy: 0.7398\n",
      "Epoch 478/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4912 - accuracy: 0.7556 - val_loss: 0.5348 - val_accuracy: 0.7398\n",
      "Epoch 479/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4907 - accuracy: 0.7536 - val_loss: 0.5348 - val_accuracy: 0.7317\n",
      "Epoch 480/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4910 - accuracy: 0.7536 - val_loss: 0.5347 - val_accuracy: 0.7317\n",
      "Epoch 481/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4902 - accuracy: 0.7536 - val_loss: 0.5345 - val_accuracy: 0.7398\n",
      "Epoch 482/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4906 - accuracy: 0.7576 - val_loss: 0.5345 - val_accuracy: 0.7398\n",
      "Epoch 483/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4901 - accuracy: 0.7556 - val_loss: 0.5345 - val_accuracy: 0.7317\n",
      "Epoch 484/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4900 - accuracy: 0.7515 - val_loss: 0.5344 - val_accuracy: 0.7317\n",
      "Epoch 485/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4895 - accuracy: 0.7515 - val_loss: 0.5343 - val_accuracy: 0.7398\n",
      "Epoch 486/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4894 - accuracy: 0.7536 - val_loss: 0.5342 - val_accuracy: 0.7317\n",
      "Epoch 487/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4890 - accuracy: 0.7556 - val_loss: 0.5342 - val_accuracy: 0.7317\n",
      "Epoch 488/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4888 - accuracy: 0.7556 - val_loss: 0.5342 - val_accuracy: 0.7398\n",
      "Epoch 489/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4887 - accuracy: 0.7556 - val_loss: 0.5340 - val_accuracy: 0.7317\n",
      "Epoch 490/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4887 - accuracy: 0.7597 - val_loss: 0.5339 - val_accuracy: 0.7398\n",
      "Epoch 491/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4882 - accuracy: 0.7515 - val_loss: 0.5339 - val_accuracy: 0.7398\n",
      "Epoch 492/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4890 - accuracy: 0.7576 - val_loss: 0.5339 - val_accuracy: 0.7398\n",
      "Epoch 493/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4880 - accuracy: 0.7556 - val_loss: 0.5338 - val_accuracy: 0.7398\n",
      "Epoch 494/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4881 - accuracy: 0.7597 - val_loss: 0.5338 - val_accuracy: 0.7398\n",
      "Epoch 495/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4876 - accuracy: 0.7556 - val_loss: 0.5338 - val_accuracy: 0.7398\n",
      "Epoch 496/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4873 - accuracy: 0.7495 - val_loss: 0.5338 - val_accuracy: 0.7317\n",
      "Epoch 497/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4869 - accuracy: 0.7515 - val_loss: 0.5336 - val_accuracy: 0.7398\n",
      "Epoch 498/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4870 - accuracy: 0.7556 - val_loss: 0.5335 - val_accuracy: 0.7398\n",
      "Epoch 499/1000\n",
      "491/491 [==============================] - 0s 36us/step - loss: 0.4870 - accuracy: 0.7597 - val_loss: 0.5335 - val_accuracy: 0.7480\n",
      "Epoch 500/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4867 - accuracy: 0.7536 - val_loss: 0.5336 - val_accuracy: 0.7236\n",
      "Epoch 501/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4866 - accuracy: 0.7658 - val_loss: 0.5334 - val_accuracy: 0.7398\n",
      "Epoch 502/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4867 - accuracy: 0.7576 - val_loss: 0.5333 - val_accuracy: 0.7398\n",
      "Epoch 503/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4862 - accuracy: 0.7617 - val_loss: 0.5335 - val_accuracy: 0.7398\n",
      "Epoch 504/1000\n",
      "491/491 [==============================] - 0s 35us/step - loss: 0.4860 - accuracy: 0.7536 - val_loss: 0.5333 - val_accuracy: 0.7317\n",
      "Epoch 505/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4861 - accuracy: 0.7495 - val_loss: 0.5332 - val_accuracy: 0.7398\n",
      "Epoch 506/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4857 - accuracy: 0.7556 - val_loss: 0.5333 - val_accuracy: 0.7398\n",
      "Epoch 507/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4855 - accuracy: 0.7576 - val_loss: 0.5332 - val_accuracy: 0.7317\n",
      "Epoch 508/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4851 - accuracy: 0.7515 - val_loss: 0.5331 - val_accuracy: 0.7317\n",
      "Epoch 509/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4857 - accuracy: 0.7536 - val_loss: 0.5330 - val_accuracy: 0.7317\n",
      "Epoch 510/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4848 - accuracy: 0.7617 - val_loss: 0.5330 - val_accuracy: 0.7398\n",
      "Epoch 511/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4846 - accuracy: 0.7576 - val_loss: 0.5329 - val_accuracy: 0.7398\n",
      "Epoch 512/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4848 - accuracy: 0.7536 - val_loss: 0.5328 - val_accuracy: 0.7398\n",
      "Epoch 513/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4842 - accuracy: 0.7536 - val_loss: 0.5328 - val_accuracy: 0.7398\n",
      "Epoch 514/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4844 - accuracy: 0.7576 - val_loss: 0.5328 - val_accuracy: 0.7398\n",
      "Epoch 515/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4842 - accuracy: 0.7597 - val_loss: 0.5328 - val_accuracy: 0.7317\n",
      "Epoch 516/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4837 - accuracy: 0.7617 - val_loss: 0.5329 - val_accuracy: 0.7398\n",
      "Epoch 517/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4833 - accuracy: 0.7576 - val_loss: 0.5328 - val_accuracy: 0.7398\n",
      "Epoch 518/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4841 - accuracy: 0.7556 - val_loss: 0.5326 - val_accuracy: 0.7317\n",
      "Epoch 519/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4836 - accuracy: 0.7576 - val_loss: 0.5326 - val_accuracy: 0.7317\n",
      "Epoch 520/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4833 - accuracy: 0.7576 - val_loss: 0.5326 - val_accuracy: 0.7317\n",
      "Epoch 521/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4833 - accuracy: 0.7536 - val_loss: 0.5325 - val_accuracy: 0.7317\n",
      "Epoch 522/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4829 - accuracy: 0.7556 - val_loss: 0.5325 - val_accuracy: 0.7317\n",
      "Epoch 523/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4828 - accuracy: 0.7617 - val_loss: 0.5326 - val_accuracy: 0.7236\n",
      "Epoch 524/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4827 - accuracy: 0.7597 - val_loss: 0.5325 - val_accuracy: 0.7317\n",
      "Epoch 525/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4823 - accuracy: 0.7576 - val_loss: 0.5325 - val_accuracy: 0.7236\n",
      "Epoch 526/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4823 - accuracy: 0.7597 - val_loss: 0.5324 - val_accuracy: 0.7317\n",
      "Epoch 527/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4821 - accuracy: 0.7576 - val_loss: 0.5323 - val_accuracy: 0.7317\n",
      "Epoch 528/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4819 - accuracy: 0.7576 - val_loss: 0.5323 - val_accuracy: 0.7317\n",
      "Epoch 529/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4817 - accuracy: 0.7576 - val_loss: 0.5323 - val_accuracy: 0.7317\n",
      "Epoch 530/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4817 - accuracy: 0.7597 - val_loss: 0.5324 - val_accuracy: 0.7236\n",
      "Epoch 531/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4820 - accuracy: 0.7576 - val_loss: 0.5322 - val_accuracy: 0.7317\n",
      "Epoch 532/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4816 - accuracy: 0.7617 - val_loss: 0.5322 - val_accuracy: 0.7317\n",
      "Epoch 533/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4814 - accuracy: 0.7576 - val_loss: 0.5322 - val_accuracy: 0.7317\n",
      "Epoch 534/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4810 - accuracy: 0.7597 - val_loss: 0.5323 - val_accuracy: 0.7236\n",
      "Epoch 535/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4814 - accuracy: 0.7576 - val_loss: 0.5322 - val_accuracy: 0.7317\n",
      "Epoch 536/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4810 - accuracy: 0.7556 - val_loss: 0.5321 - val_accuracy: 0.7317\n",
      "Epoch 537/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4807 - accuracy: 0.7576 - val_loss: 0.5321 - val_accuracy: 0.7398\n",
      "Epoch 538/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4810 - accuracy: 0.7637 - val_loss: 0.5321 - val_accuracy: 0.7317\n",
      "Epoch 539/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4801 - accuracy: 0.7617 - val_loss: 0.5321 - val_accuracy: 0.7317\n",
      "Epoch 540/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4806 - accuracy: 0.7617 - val_loss: 0.5321 - val_accuracy: 0.7317\n",
      "Epoch 541/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4799 - accuracy: 0.7597 - val_loss: 0.5321 - val_accuracy: 0.7317\n",
      "Epoch 542/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4800 - accuracy: 0.7617 - val_loss: 0.5320 - val_accuracy: 0.7398\n",
      "Epoch 543/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4797 - accuracy: 0.7597 - val_loss: 0.5323 - val_accuracy: 0.7073\n",
      "Epoch 544/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4806 - accuracy: 0.7637 - val_loss: 0.5320 - val_accuracy: 0.7236\n",
      "Epoch 545/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4801 - accuracy: 0.7637 - val_loss: 0.5320 - val_accuracy: 0.7154\n",
      "Epoch 546/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4791 - accuracy: 0.7637 - val_loss: 0.5321 - val_accuracy: 0.7236\n",
      "Epoch 547/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4800 - accuracy: 0.7576 - val_loss: 0.5319 - val_accuracy: 0.7317\n",
      "Epoch 548/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4790 - accuracy: 0.7637 - val_loss: 0.5319 - val_accuracy: 0.7317\n",
      "Epoch 549/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4791 - accuracy: 0.7658 - val_loss: 0.5319 - val_accuracy: 0.7317\n",
      "Epoch 550/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4786 - accuracy: 0.7597 - val_loss: 0.5319 - val_accuracy: 0.7317\n",
      "Epoch 551/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4789 - accuracy: 0.7597 - val_loss: 0.5319 - val_accuracy: 0.7317\n",
      "Epoch 552/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4791 - accuracy: 0.7658 - val_loss: 0.5319 - val_accuracy: 0.7236\n",
      "Epoch 553/1000\n",
      "491/491 [==============================] - 0s 32us/step - loss: 0.4783 - accuracy: 0.7637 - val_loss: 0.5319 - val_accuracy: 0.7154\n",
      "Epoch 554/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4788 - accuracy: 0.7658 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 555/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4779 - accuracy: 0.7637 - val_loss: 0.5318 - val_accuracy: 0.7317\n",
      "Epoch 556/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4783 - accuracy: 0.7617 - val_loss: 0.5319 - val_accuracy: 0.7154\n",
      "Epoch 557/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4779 - accuracy: 0.7658 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 558/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4778 - accuracy: 0.7658 - val_loss: 0.5318 - val_accuracy: 0.7317\n",
      "Epoch 559/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4780 - accuracy: 0.7617 - val_loss: 0.5319 - val_accuracy: 0.7317\n",
      "Epoch 560/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4775 - accuracy: 0.7637 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 561/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4780 - accuracy: 0.7617 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 562/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4780 - accuracy: 0.7637 - val_loss: 0.5318 - val_accuracy: 0.7317\n",
      "Epoch 563/1000\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.4778 - accuracy: 0.7637 - val_loss: 0.5318 - val_accuracy: 0.7154\n",
      "Epoch 564/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4769 - accuracy: 0.7678 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 565/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4766 - accuracy: 0.7658 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 566/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4769 - accuracy: 0.7678 - val_loss: 0.5318 - val_accuracy: 0.7317\n",
      "Epoch 567/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4762 - accuracy: 0.7637 - val_loss: 0.5318 - val_accuracy: 0.7154\n",
      "Epoch 568/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4762 - accuracy: 0.7678 - val_loss: 0.5318 - val_accuracy: 0.7317\n",
      "Epoch 569/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4760 - accuracy: 0.7678 - val_loss: 0.5318 - val_accuracy: 0.7154\n",
      "Epoch 570/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4760 - accuracy: 0.7658 - val_loss: 0.5318 - val_accuracy: 0.7317\n",
      "Epoch 571/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4759 - accuracy: 0.7658 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 572/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4758 - accuracy: 0.7678 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 573/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4758 - accuracy: 0.7637 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 574/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4755 - accuracy: 0.7699 - val_loss: 0.5317 - val_accuracy: 0.7236\n",
      "Epoch 575/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4753 - accuracy: 0.7658 - val_loss: 0.5317 - val_accuracy: 0.7236\n",
      "Epoch 576/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4761 - accuracy: 0.7678 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 577/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4761 - accuracy: 0.7658 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 578/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4755 - accuracy: 0.7678 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 579/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4758 - accuracy: 0.7699 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 580/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4751 - accuracy: 0.7678 - val_loss: 0.5318 - val_accuracy: 0.7317\n",
      "Epoch 581/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4748 - accuracy: 0.7699 - val_loss: 0.5318 - val_accuracy: 0.7317\n",
      "Epoch 582/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4754 - accuracy: 0.7658 - val_loss: 0.5318 - val_accuracy: 0.7317\n",
      "Epoch 583/1000\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.73 - 0s 24us/step - loss: 0.4750 - accuracy: 0.7678 - val_loss: 0.5320 - val_accuracy: 0.7480\n",
      "Epoch 584/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4748 - accuracy: 0.7678 - val_loss: 0.5320 - val_accuracy: 0.7480\n",
      "Epoch 585/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4741 - accuracy: 0.7658 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 586/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4742 - accuracy: 0.7678 - val_loss: 0.5319 - val_accuracy: 0.7317\n",
      "Epoch 587/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4744 - accuracy: 0.7637 - val_loss: 0.5319 - val_accuracy: 0.7236\n",
      "Epoch 588/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4743 - accuracy: 0.7678 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
      "Epoch 589/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4744 - accuracy: 0.7658 - val_loss: 0.5319 - val_accuracy: 0.7236\n",
      "Epoch 590/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4741 - accuracy: 0.7678 - val_loss: 0.5319 - val_accuracy: 0.7236\n",
      "Epoch 591/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4737 - accuracy: 0.7719 - val_loss: 0.5320 - val_accuracy: 0.7317\n",
      "Epoch 592/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4739 - accuracy: 0.7699 - val_loss: 0.5319 - val_accuracy: 0.7236\n",
      "Epoch 593/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4741 - accuracy: 0.7719 - val_loss: 0.5320 - val_accuracy: 0.7236\n",
      "Epoch 594/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4735 - accuracy: 0.7678 - val_loss: 0.5321 - val_accuracy: 0.7317\n",
      "Epoch 595/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4731 - accuracy: 0.7658 - val_loss: 0.5320 - val_accuracy: 0.7236\n",
      "Epoch 596/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4730 - accuracy: 0.7658 - val_loss: 0.5320 - val_accuracy: 0.7398\n",
      "Epoch 597/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4732 - accuracy: 0.7658 - val_loss: 0.5320 - val_accuracy: 0.7236\n",
      "Epoch 598/1000\n",
      "491/491 [==============================] - 0s 17us/step - loss: 0.4732 - accuracy: 0.7678 - val_loss: 0.5321 - val_accuracy: 0.7398\n",
      "Epoch 599/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4728 - accuracy: 0.7699 - val_loss: 0.5320 - val_accuracy: 0.7236\n",
      "Epoch 600/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4728 - accuracy: 0.7678 - val_loss: 0.5320 - val_accuracy: 0.7236\n",
      "Epoch 601/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4739 - accuracy: 0.7699 - val_loss: 0.5322 - val_accuracy: 0.7317\n",
      "Epoch 602/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4729 - accuracy: 0.7658 - val_loss: 0.5320 - val_accuracy: 0.7236\n",
      "Epoch 603/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4723 - accuracy: 0.7637 - val_loss: 0.5320 - val_accuracy: 0.7236\n",
      "Epoch 604/1000\n",
      "491/491 [==============================] - 0s 17us/step - loss: 0.4722 - accuracy: 0.7678 - val_loss: 0.5321 - val_accuracy: 0.7236\n",
      "Epoch 605/1000\n",
      "491/491 [==============================] - 0s 17us/step - loss: 0.4723 - accuracy: 0.7658 - val_loss: 0.5321 - val_accuracy: 0.7398\n",
      "Epoch 606/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4725 - accuracy: 0.7678 - val_loss: 0.5321 - val_accuracy: 0.7398\n",
      "Epoch 607/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4725 - accuracy: 0.7637 - val_loss: 0.5321 - val_accuracy: 0.7317\n",
      "Epoch 608/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4718 - accuracy: 0.7637 - val_loss: 0.5321 - val_accuracy: 0.7236\n",
      "Epoch 609/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4721 - accuracy: 0.7658 - val_loss: 0.5321 - val_accuracy: 0.7398\n",
      "Epoch 610/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4725 - accuracy: 0.7637 - val_loss: 0.5322 - val_accuracy: 0.7154\n",
      "Epoch 611/1000\n",
      "491/491 [==============================] - 0s 17us/step - loss: 0.4719 - accuracy: 0.7637 - val_loss: 0.5322 - val_accuracy: 0.7236\n",
      "Epoch 612/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4716 - accuracy: 0.7678 - val_loss: 0.5322 - val_accuracy: 0.7236\n",
      "Epoch 613/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4714 - accuracy: 0.7699 - val_loss: 0.5322 - val_accuracy: 0.7317\n",
      "Epoch 614/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4718 - accuracy: 0.7658 - val_loss: 0.5322 - val_accuracy: 0.7398\n",
      "Epoch 615/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4718 - accuracy: 0.7678 - val_loss: 0.5323 - val_accuracy: 0.7236\n",
      "Epoch 616/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4716 - accuracy: 0.7658 - val_loss: 0.5323 - val_accuracy: 0.7236\n",
      "Epoch 617/1000\n",
      "491/491 [==============================] - 0s 15us/step - loss: 0.4716 - accuracy: 0.7637 - val_loss: 0.5323 - val_accuracy: 0.7236\n",
      "Epoch 618/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4710 - accuracy: 0.7617 - val_loss: 0.5322 - val_accuracy: 0.7236\n",
      "Epoch 619/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4709 - accuracy: 0.7658 - val_loss: 0.5322 - val_accuracy: 0.7236\n",
      "Epoch 620/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4708 - accuracy: 0.7658 - val_loss: 0.5322 - val_accuracy: 0.7236\n",
      "Epoch 621/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4711 - accuracy: 0.7678 - val_loss: 0.5325 - val_accuracy: 0.7154\n",
      "Epoch 622/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4720 - accuracy: 0.7637 - val_loss: 0.5326 - val_accuracy: 0.7154\n",
      "Epoch 623/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4714 - accuracy: 0.7719 - val_loss: 0.5330 - val_accuracy: 0.7236\n",
      "Epoch 624/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4714 - accuracy: 0.7719 - val_loss: 0.5323 - val_accuracy: 0.7236\n",
      "Epoch 625/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4714 - accuracy: 0.7678 - val_loss: 0.5323 - val_accuracy: 0.7317\n",
      "Epoch 626/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.4710 - accuracy: 0.7699 - val_loss: 0.5323 - val_accuracy: 0.7317\n",
      "Epoch 627/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4711 - accuracy: 0.7658 - val_loss: 0.5323 - val_accuracy: 0.7317\n",
      "Epoch 628/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4704 - accuracy: 0.7699 - val_loss: 0.5324 - val_accuracy: 0.7236\n",
      "Epoch 629/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4710 - accuracy: 0.7658 - val_loss: 0.5324 - val_accuracy: 0.7236\n",
      "Epoch 630/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4704 - accuracy: 0.7637 - val_loss: 0.5324 - val_accuracy: 0.7236\n",
      "Epoch 631/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4703 - accuracy: 0.7699 - val_loss: 0.5324 - val_accuracy: 0.7317\n",
      "Epoch 632/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4698 - accuracy: 0.7678 - val_loss: 0.5324 - val_accuracy: 0.7236\n",
      "Epoch 633/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4699 - accuracy: 0.7678 - val_loss: 0.5324 - val_accuracy: 0.7317\n",
      "Epoch 634/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4704 - accuracy: 0.7678 - val_loss: 0.5325 - val_accuracy: 0.7317\n",
      "Epoch 635/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4703 - accuracy: 0.7678 - val_loss: 0.5325 - val_accuracy: 0.7236\n",
      "Epoch 636/1000\n",
      "491/491 [==============================] - 0s 38us/step - loss: 0.4698 - accuracy: 0.7637 - val_loss: 0.5325 - val_accuracy: 0.7236\n",
      "Epoch 637/1000\n",
      "491/491 [==============================] - 0s 34us/step - loss: 0.4696 - accuracy: 0.7678 - val_loss: 0.5326 - val_accuracy: 0.7236\n",
      "Epoch 638/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4698 - accuracy: 0.7699 - val_loss: 0.5325 - val_accuracy: 0.7317\n",
      "Epoch 639/1000\n",
      "491/491 [==============================] - 0s 34us/step - loss: 0.4700 - accuracy: 0.7658 - val_loss: 0.5325 - val_accuracy: 0.7317\n",
      "Epoch 640/1000\n",
      "491/491 [==============================] - 0s 34us/step - loss: 0.4700 - accuracy: 0.7678 - val_loss: 0.5325 - val_accuracy: 0.7317\n",
      "Epoch 641/1000\n",
      "491/491 [==============================] - 0s 36us/step - loss: 0.4697 - accuracy: 0.7699 - val_loss: 0.5326 - val_accuracy: 0.7236\n",
      "Epoch 642/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4698 - accuracy: 0.7678 - val_loss: 0.5327 - val_accuracy: 0.7236\n",
      "Epoch 643/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4693 - accuracy: 0.7678 - val_loss: 0.5326 - val_accuracy: 0.7317\n",
      "Epoch 644/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4700 - accuracy: 0.7658 - val_loss: 0.5326 - val_accuracy: 0.7236\n",
      "Epoch 645/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4688 - accuracy: 0.7658 - val_loss: 0.5327 - val_accuracy: 0.7236\n",
      "Epoch 646/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4694 - accuracy: 0.7678 - val_loss: 0.5327 - val_accuracy: 0.7236\n",
      "Epoch 647/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4688 - accuracy: 0.7678 - val_loss: 0.5326 - val_accuracy: 0.7236\n",
      "Epoch 648/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4699 - accuracy: 0.7678 - val_loss: 0.5331 - val_accuracy: 0.7236\n",
      "Epoch 649/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4690 - accuracy: 0.7658 - val_loss: 0.5328 - val_accuracy: 0.7236\n",
      "Epoch 650/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4685 - accuracy: 0.7637 - val_loss: 0.5327 - val_accuracy: 0.7236\n",
      "Epoch 651/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4689 - accuracy: 0.7658 - val_loss: 0.5327 - val_accuracy: 0.7236\n",
      "Epoch 652/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4686 - accuracy: 0.7658 - val_loss: 0.5328 - val_accuracy: 0.7236\n",
      "Epoch 653/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4684 - accuracy: 0.7617 - val_loss: 0.5327 - val_accuracy: 0.7317\n",
      "Epoch 654/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4689 - accuracy: 0.7678 - val_loss: 0.5327 - val_accuracy: 0.7398\n",
      "Epoch 655/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4685 - accuracy: 0.7637 - val_loss: 0.5327 - val_accuracy: 0.7398\n",
      "Epoch 656/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4682 - accuracy: 0.7658 - val_loss: 0.5328 - val_accuracy: 0.7236\n",
      "Epoch 657/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4683 - accuracy: 0.7658 - val_loss: 0.5328 - val_accuracy: 0.7236\n",
      "Epoch 658/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4686 - accuracy: 0.7699 - val_loss: 0.5328 - val_accuracy: 0.7317\n",
      "Epoch 659/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4681 - accuracy: 0.7637 - val_loss: 0.5328 - val_accuracy: 0.7398\n",
      "Epoch 660/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4680 - accuracy: 0.7658 - val_loss: 0.5329 - val_accuracy: 0.7398\n",
      "Epoch 661/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4681 - accuracy: 0.7739 - val_loss: 0.5328 - val_accuracy: 0.7236\n",
      "Epoch 662/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4680 - accuracy: 0.7658 - val_loss: 0.5328 - val_accuracy: 0.7398\n",
      "Epoch 663/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4678 - accuracy: 0.7658 - val_loss: 0.5328 - val_accuracy: 0.7398\n",
      "Epoch 664/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4682 - accuracy: 0.7719 - val_loss: 0.5331 - val_accuracy: 0.7236\n",
      "Epoch 665/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4681 - accuracy: 0.7637 - val_loss: 0.5329 - val_accuracy: 0.7317\n",
      "Epoch 666/1000\n",
      "491/491 [==============================] - 0s 17us/step - loss: 0.4677 - accuracy: 0.7678 - val_loss: 0.5329 - val_accuracy: 0.7398\n",
      "Epoch 667/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4681 - accuracy: 0.7637 - val_loss: 0.5329 - val_accuracy: 0.7398\n",
      "Epoch 668/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4678 - accuracy: 0.7719 - val_loss: 0.5331 - val_accuracy: 0.7317\n",
      "Epoch 669/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4677 - accuracy: 0.7658 - val_loss: 0.5329 - val_accuracy: 0.7398\n",
      "Epoch 670/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4672 - accuracy: 0.7699 - val_loss: 0.5329 - val_accuracy: 0.7398\n",
      "Epoch 671/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4672 - accuracy: 0.7678 - val_loss: 0.5329 - val_accuracy: 0.7480\n",
      "Epoch 672/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4682 - accuracy: 0.7719 - val_loss: 0.5329 - val_accuracy: 0.7398\n",
      "Epoch 673/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4682 - accuracy: 0.7699 - val_loss: 0.5329 - val_accuracy: 0.7480\n",
      "Epoch 674/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4673 - accuracy: 0.7699 - val_loss: 0.5329 - val_accuracy: 0.7398\n",
      "Epoch 675/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4679 - accuracy: 0.7699 - val_loss: 0.5330 - val_accuracy: 0.7480\n",
      "Epoch 676/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4682 - accuracy: 0.7760 - val_loss: 0.5330 - val_accuracy: 0.7317\n",
      "Epoch 677/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4674 - accuracy: 0.7637 - val_loss: 0.5330 - val_accuracy: 0.7480\n",
      "Epoch 678/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4671 - accuracy: 0.7699 - val_loss: 0.5330 - val_accuracy: 0.7398\n",
      "Epoch 679/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4669 - accuracy: 0.7760 - val_loss: 0.5332 - val_accuracy: 0.7398\n",
      "Epoch 680/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4670 - accuracy: 0.7699 - val_loss: 0.5330 - val_accuracy: 0.7398\n",
      "Epoch 681/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4670 - accuracy: 0.7719 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 682/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4669 - accuracy: 0.7719 - val_loss: 0.5331 - val_accuracy: 0.7398\n",
      "Epoch 683/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4670 - accuracy: 0.7678 - val_loss: 0.5332 - val_accuracy: 0.7398\n",
      "Epoch 684/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4667 - accuracy: 0.7678 - val_loss: 0.5332 - val_accuracy: 0.7317\n",
      "Epoch 685/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4671 - accuracy: 0.7658 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 686/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4671 - accuracy: 0.7617 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 687/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4669 - accuracy: 0.7678 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 688/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4667 - accuracy: 0.7719 - val_loss: 0.5332 - val_accuracy: 0.7398\n",
      "Epoch 689/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4663 - accuracy: 0.7699 - val_loss: 0.5331 - val_accuracy: 0.7398\n",
      "Epoch 690/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4666 - accuracy: 0.7658 - val_loss: 0.5332 - val_accuracy: 0.7398\n",
      "Epoch 691/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4667 - accuracy: 0.7658 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 692/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4666 - accuracy: 0.7678 - val_loss: 0.5332 - val_accuracy: 0.7398\n",
      "Epoch 693/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4664 - accuracy: 0.7760 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 694/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4660 - accuracy: 0.7678 - val_loss: 0.5330 - val_accuracy: 0.7480\n",
      "Epoch 695/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4666 - accuracy: 0.7760 - val_loss: 0.5337 - val_accuracy: 0.7236\n",
      "Epoch 696/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4666 - accuracy: 0.7617 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 697/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4670 - accuracy: 0.7699 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 698/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4658 - accuracy: 0.7678 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 699/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4664 - accuracy: 0.7739 - val_loss: 0.5331 - val_accuracy: 0.7561\n",
      "Epoch 700/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4663 - accuracy: 0.7637 - val_loss: 0.5334 - val_accuracy: 0.7398\n",
      "Epoch 701/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4659 - accuracy: 0.7617 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 702/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4656 - accuracy: 0.7617 - val_loss: 0.5332 - val_accuracy: 0.7480\n",
      "Epoch 703/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4666 - accuracy: 0.7699 - val_loss: 0.5332 - val_accuracy: 0.7480\n",
      "Epoch 704/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4661 - accuracy: 0.7678 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 705/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4656 - accuracy: 0.7637 - val_loss: 0.5334 - val_accuracy: 0.7398\n",
      "Epoch 706/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4661 - accuracy: 0.7739 - val_loss: 0.5331 - val_accuracy: 0.7561\n",
      "Epoch 707/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4659 - accuracy: 0.7658 - val_loss: 0.5332 - val_accuracy: 0.7480\n",
      "Epoch 708/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4657 - accuracy: 0.7719 - val_loss: 0.5332 - val_accuracy: 0.7561\n",
      "Epoch 709/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4662 - accuracy: 0.7719 - val_loss: 0.5333 - val_accuracy: 0.7480\n",
      "Epoch 710/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4653 - accuracy: 0.7658 - val_loss: 0.5332 - val_accuracy: 0.7561\n",
      "Epoch 711/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4659 - accuracy: 0.7678 - val_loss: 0.5332 - val_accuracy: 0.7480\n",
      "Epoch 712/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4655 - accuracy: 0.7678 - val_loss: 0.5332 - val_accuracy: 0.7561\n",
      "Epoch 713/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4654 - accuracy: 0.7699 - val_loss: 0.5334 - val_accuracy: 0.7398\n",
      "Epoch 714/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4658 - accuracy: 0.7699 - val_loss: 0.5334 - val_accuracy: 0.7398\n",
      "Epoch 715/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4658 - accuracy: 0.7760 - val_loss: 0.5333 - val_accuracy: 0.7480\n",
      "Epoch 716/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4659 - accuracy: 0.7719 - val_loss: 0.5335 - val_accuracy: 0.7398\n",
      "Epoch 717/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4658 - accuracy: 0.7739 - val_loss: 0.5333 - val_accuracy: 0.7480\n",
      "Epoch 718/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4649 - accuracy: 0.7719 - val_loss: 0.5334 - val_accuracy: 0.7480\n",
      "Epoch 719/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4664 - accuracy: 0.7658 - val_loss: 0.5333 - val_accuracy: 0.7480\n",
      "Epoch 720/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4651 - accuracy: 0.7658 - val_loss: 0.5333 - val_accuracy: 0.7480\n",
      "Epoch 721/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4658 - accuracy: 0.7699 - val_loss: 0.5333 - val_accuracy: 0.7561\n",
      "Epoch 722/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4654 - accuracy: 0.7637 - val_loss: 0.5333 - val_accuracy: 0.7480\n",
      "Epoch 723/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4650 - accuracy: 0.7678 - val_loss: 0.5333 - val_accuracy: 0.7480\n",
      "Epoch 724/1000\n",
      "491/491 [==============================] - 0s 34us/step - loss: 0.4648 - accuracy: 0.7678 - val_loss: 0.5336 - val_accuracy: 0.7398\n",
      "Epoch 725/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.4657 - accuracy: 0.7739 - val_loss: 0.5334 - val_accuracy: 0.7480\n",
      "Epoch 726/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.4649 - accuracy: 0.7699 - val_loss: 0.5333 - val_accuracy: 0.7561\n",
      "Epoch 727/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4657 - accuracy: 0.7678 - val_loss: 0.5333 - val_accuracy: 0.7561\n",
      "Epoch 728/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4646 - accuracy: 0.7678 - val_loss: 0.5333 - val_accuracy: 0.7561\n",
      "Epoch 729/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4646 - accuracy: 0.7699 - val_loss: 0.5335 - val_accuracy: 0.7480\n",
      "Epoch 730/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4655 - accuracy: 0.7658 - val_loss: 0.5335 - val_accuracy: 0.7480\n",
      "Epoch 731/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.5336 - val_accuracy: 0.7480\n",
      "Epoch 732/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4649 - accuracy: 0.7678 - val_loss: 0.5337 - val_accuracy: 0.7398\n",
      "Epoch 733/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4658 - accuracy: 0.7658 - val_loss: 0.5339 - val_accuracy: 0.7398\n",
      "Epoch 734/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4646 - accuracy: 0.7739 - val_loss: 0.5335 - val_accuracy: 0.7561\n",
      "Epoch 735/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4652 - accuracy: 0.7678 - val_loss: 0.5336 - val_accuracy: 0.7561\n",
      "Epoch 736/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4652 - accuracy: 0.7658 - val_loss: 0.5335 - val_accuracy: 0.7561\n",
      "Epoch 737/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4649 - accuracy: 0.7678 - val_loss: 0.5335 - val_accuracy: 0.7480\n",
      "Epoch 738/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4650 - accuracy: 0.7699 - val_loss: 0.5337 - val_accuracy: 0.7480\n",
      "Epoch 739/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4655 - accuracy: 0.7699 - val_loss: 0.5338 - val_accuracy: 0.7480\n",
      "Epoch 740/1000\n",
      "491/491 [==============================] - 0s 21us/step - loss: 0.4649 - accuracy: 0.7637 - val_loss: 0.5336 - val_accuracy: 0.7480\n",
      "Epoch 741/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4646 - accuracy: 0.7637 - val_loss: 0.5335 - val_accuracy: 0.7561\n",
      "Epoch 742/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4645 - accuracy: 0.7678 - val_loss: 0.5335 - val_accuracy: 0.7561\n",
      "Epoch 743/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4647 - accuracy: 0.7637 - val_loss: 0.5335 - val_accuracy: 0.7561\n",
      "Epoch 744/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4643 - accuracy: 0.7617 - val_loss: 0.5337 - val_accuracy: 0.7480\n",
      "Epoch 745/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4643 - accuracy: 0.7739 - val_loss: 0.5336 - val_accuracy: 0.7561\n",
      "Epoch 746/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4643 - accuracy: 0.7637 - val_loss: 0.5339 - val_accuracy: 0.7480\n",
      "Epoch 747/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4644 - accuracy: 0.7719 - val_loss: 0.5337 - val_accuracy: 0.7480\n",
      "Epoch 748/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4642 - accuracy: 0.7739 - val_loss: 0.5335 - val_accuracy: 0.7561\n",
      "Epoch 749/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4644 - accuracy: 0.7739 - val_loss: 0.5336 - val_accuracy: 0.7480\n",
      "Epoch 750/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4643 - accuracy: 0.7800 - val_loss: 0.5337 - val_accuracy: 0.7480\n",
      "Epoch 751/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4641 - accuracy: 0.7658 - val_loss: 0.5336 - val_accuracy: 0.7561\n",
      "Epoch 752/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4641 - accuracy: 0.7658 - val_loss: 0.5336 - val_accuracy: 0.7561\n",
      "Epoch 753/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4649 - accuracy: 0.7678 - val_loss: 0.5339 - val_accuracy: 0.7480\n",
      "Epoch 754/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4639 - accuracy: 0.7658 - val_loss: 0.5338 - val_accuracy: 0.7480\n",
      "Epoch 755/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4639 - accuracy: 0.7637 - val_loss: 0.5336 - val_accuracy: 0.7561\n",
      "Epoch 756/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4636 - accuracy: 0.7617 - val_loss: 0.5338 - val_accuracy: 0.7480\n",
      "Epoch 757/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4643 - accuracy: 0.7719 - val_loss: 0.5336 - val_accuracy: 0.7561\n",
      "Epoch 758/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4640 - accuracy: 0.7678 - val_loss: 0.5336 - val_accuracy: 0.7561\n",
      "Epoch 759/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4654 - accuracy: 0.7637 - val_loss: 0.5337 - val_accuracy: 0.7561\n",
      "Epoch 760/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4637 - accuracy: 0.7719 - val_loss: 0.5337 - val_accuracy: 0.7561\n",
      "Epoch 761/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4636 - accuracy: 0.7637 - val_loss: 0.5337 - val_accuracy: 0.7561\n",
      "Epoch 762/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4635 - accuracy: 0.7658 - val_loss: 0.5338 - val_accuracy: 0.7480\n",
      "Epoch 763/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4646 - accuracy: 0.7719 - val_loss: 0.5338 - val_accuracy: 0.7561\n",
      "Epoch 764/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4639 - accuracy: 0.7658 - val_loss: 0.5338 - val_accuracy: 0.7561\n",
      "Epoch 765/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4639 - accuracy: 0.7739 - val_loss: 0.5338 - val_accuracy: 0.7561\n",
      "Epoch 766/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4637 - accuracy: 0.7678 - val_loss: 0.5339 - val_accuracy: 0.7561\n",
      "Epoch 767/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4634 - accuracy: 0.7739 - val_loss: 0.5339 - val_accuracy: 0.7561\n",
      "Epoch 768/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4639 - accuracy: 0.7678 - val_loss: 0.5339 - val_accuracy: 0.7561\n",
      "Epoch 769/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4636 - accuracy: 0.7719 - val_loss: 0.5345 - val_accuracy: 0.7480\n",
      "Epoch 770/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.5341 - val_accuracy: 0.7398\n",
      "Epoch 771/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4640 - accuracy: 0.7637 - val_loss: 0.5339 - val_accuracy: 0.7561\n",
      "Epoch 772/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4633 - accuracy: 0.7699 - val_loss: 0.5342 - val_accuracy: 0.7398\n",
      "Epoch 773/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4632 - accuracy: 0.7678 - val_loss: 0.5341 - val_accuracy: 0.7398\n",
      "Epoch 774/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4646 - accuracy: 0.7739 - val_loss: 0.5339 - val_accuracy: 0.7561\n",
      "Epoch 775/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4635 - accuracy: 0.7678 - val_loss: 0.5339 - val_accuracy: 0.7561\n",
      "Epoch 776/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4631 - accuracy: 0.7699 - val_loss: 0.5339 - val_accuracy: 0.7561\n",
      "Epoch 777/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4629 - accuracy: 0.7678 - val_loss: 0.5340 - val_accuracy: 0.7561\n",
      "Epoch 778/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4634 - accuracy: 0.7699 - val_loss: 0.5340 - val_accuracy: 0.7561\n",
      "Epoch 779/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4629 - accuracy: 0.7678 - val_loss: 0.5341 - val_accuracy: 0.7561\n",
      "Epoch 780/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4629 - accuracy: 0.7719 - val_loss: 0.5341 - val_accuracy: 0.7561\n",
      "Epoch 781/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4632 - accuracy: 0.7699 - val_loss: 0.5340 - val_accuracy: 0.7561\n",
      "Epoch 782/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4633 - accuracy: 0.7637 - val_loss: 0.5340 - val_accuracy: 0.7561\n",
      "Epoch 783/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4643 - accuracy: 0.7678 - val_loss: 0.5341 - val_accuracy: 0.7561\n",
      "Epoch 784/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4628 - accuracy: 0.7678 - val_loss: 0.5340 - val_accuracy: 0.7561\n",
      "Epoch 785/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4627 - accuracy: 0.7678 - val_loss: 0.5343 - val_accuracy: 0.7398\n",
      "Epoch 786/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4636 - accuracy: 0.7739 - val_loss: 0.5342 - val_accuracy: 0.7398\n",
      "Epoch 787/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4631 - accuracy: 0.7760 - val_loss: 0.5340 - val_accuracy: 0.7561\n",
      "Epoch 788/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4630 - accuracy: 0.7637 - val_loss: 0.5341 - val_accuracy: 0.7561\n",
      "Epoch 789/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4631 - accuracy: 0.7699 - val_loss: 0.5341 - val_accuracy: 0.7561\n",
      "Epoch 790/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4628 - accuracy: 0.7678 - val_loss: 0.5344 - val_accuracy: 0.7398\n",
      "Epoch 791/1000\n",
      "491/491 [==============================] - 0s 16us/step - loss: 0.4639 - accuracy: 0.7719 - val_loss: 0.5341 - val_accuracy: 0.7561\n",
      "Epoch 792/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4631 - accuracy: 0.7678 - val_loss: 0.5342 - val_accuracy: 0.7561\n",
      "Epoch 793/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4628 - accuracy: 0.7678 - val_loss: 0.5343 - val_accuracy: 0.7561\n",
      "Epoch 794/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4625 - accuracy: 0.7678 - val_loss: 0.5343 - val_accuracy: 0.7480\n",
      "Epoch 795/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4637 - accuracy: 0.7699 - val_loss: 0.5343 - val_accuracy: 0.7561\n",
      "Epoch 796/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4631 - accuracy: 0.7760 - val_loss: 0.5342 - val_accuracy: 0.7561\n",
      "Epoch 797/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4641 - accuracy: 0.7719 - val_loss: 0.5343 - val_accuracy: 0.7561\n",
      "Epoch 798/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4624 - accuracy: 0.7658 - val_loss: 0.5342 - val_accuracy: 0.7561\n",
      "Epoch 799/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4626 - accuracy: 0.7719 - val_loss: 0.5345 - val_accuracy: 0.7561\n",
      "Epoch 800/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4627 - accuracy: 0.7658 - val_loss: 0.5346 - val_accuracy: 0.7480\n",
      "Epoch 801/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4630 - accuracy: 0.7678 - val_loss: 0.5343 - val_accuracy: 0.7561\n",
      "Epoch 802/1000\n",
      "491/491 [==============================] - 0s 23us/step - loss: 0.4623 - accuracy: 0.7699 - val_loss: 0.5344 - val_accuracy: 0.7561\n",
      "Epoch 803/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4629 - accuracy: 0.7699 - val_loss: 0.5344 - val_accuracy: 0.7561\n",
      "Epoch 804/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4623 - accuracy: 0.7658 - val_loss: 0.5344 - val_accuracy: 0.7561\n",
      "Epoch 805/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4621 - accuracy: 0.7699 - val_loss: 0.5344 - val_accuracy: 0.7561\n",
      "Epoch 806/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4637 - accuracy: 0.7699 - val_loss: 0.5349 - val_accuracy: 0.7398\n",
      "Epoch 807/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4627 - accuracy: 0.7678 - val_loss: 0.5345 - val_accuracy: 0.7561\n",
      "Epoch 808/1000\n",
      "491/491 [==============================] - 0s 33us/step - loss: 0.4623 - accuracy: 0.7699 - val_loss: 0.5345 - val_accuracy: 0.7561\n",
      "Epoch 809/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4630 - accuracy: 0.7719 - val_loss: 0.5350 - val_accuracy: 0.7480\n",
      "Epoch 810/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4625 - accuracy: 0.7719 - val_loss: 0.5345 - val_accuracy: 0.7561\n",
      "Epoch 811/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4632 - accuracy: 0.7637 - val_loss: 0.5347 - val_accuracy: 0.7561\n",
      "Epoch 812/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4630 - accuracy: 0.7699 - val_loss: 0.5345 - val_accuracy: 0.7561\n",
      "Epoch 813/1000\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.4622 - accuracy: 0.7699 - val_loss: 0.5346 - val_accuracy: 0.7561\n",
      "Epoch 814/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4621 - accuracy: 0.7719 - val_loss: 0.5347 - val_accuracy: 0.7480\n",
      "Epoch 815/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4621 - accuracy: 0.7780 - val_loss: 0.5345 - val_accuracy: 0.7561\n",
      "Epoch 816/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4623 - accuracy: 0.7678 - val_loss: 0.5345 - val_accuracy: 0.7561\n",
      "Epoch 817/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4622 - accuracy: 0.7658 - val_loss: 0.5345 - val_accuracy: 0.7561\n",
      "Epoch 818/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4627 - accuracy: 0.7678 - val_loss: 0.5345 - val_accuracy: 0.7561\n",
      "Epoch 819/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4640 - accuracy: 0.7719 - val_loss: 0.5345 - val_accuracy: 0.7561\n",
      "Epoch 820/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4622 - accuracy: 0.7658 - val_loss: 0.5347 - val_accuracy: 0.7561\n",
      "Epoch 821/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4633 - accuracy: 0.7739 - val_loss: 0.5345 - val_accuracy: 0.7561\n",
      "Epoch 822/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4619 - accuracy: 0.7678 - val_loss: 0.5348 - val_accuracy: 0.7480\n",
      "Epoch 823/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4621 - accuracy: 0.7719 - val_loss: 0.5346 - val_accuracy: 0.7561\n",
      "Epoch 824/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4621 - accuracy: 0.7658 - val_loss: 0.5350 - val_accuracy: 0.7480\n",
      "Epoch 825/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4619 - accuracy: 0.7780 - val_loss: 0.5346 - val_accuracy: 0.7561\n",
      "Epoch 826/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4617 - accuracy: 0.7699 - val_loss: 0.5347 - val_accuracy: 0.7561\n",
      "Epoch 827/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4627 - accuracy: 0.7699 - val_loss: 0.5347 - val_accuracy: 0.7561\n",
      "Epoch 828/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4620 - accuracy: 0.7719 - val_loss: 0.5347 - val_accuracy: 0.7561\n",
      "Epoch 829/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4622 - accuracy: 0.7719 - val_loss: 0.5346 - val_accuracy: 0.7561\n",
      "Epoch 830/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4625 - accuracy: 0.7699 - val_loss: 0.5351 - val_accuracy: 0.7480\n",
      "Epoch 831/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4619 - accuracy: 0.7699 - val_loss: 0.5347 - val_accuracy: 0.7561\n",
      "Epoch 832/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4619 - accuracy: 0.7739 - val_loss: 0.5346 - val_accuracy: 0.7561\n",
      "Epoch 833/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4625 - accuracy: 0.7739 - val_loss: 0.5347 - val_accuracy: 0.7561\n",
      "Epoch 834/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4623 - accuracy: 0.7699 - val_loss: 0.5347 - val_accuracy: 0.7561\n",
      "Epoch 835/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4628 - accuracy: 0.7719 - val_loss: 0.5349 - val_accuracy: 0.7561\n",
      "Epoch 836/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4626 - accuracy: 0.7699 - val_loss: 0.5350 - val_accuracy: 0.7480\n",
      "Epoch 837/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4614 - accuracy: 0.7678 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 838/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4618 - accuracy: 0.7658 - val_loss: 0.5352 - val_accuracy: 0.7480\n",
      "Epoch 839/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4617 - accuracy: 0.7719 - val_loss: 0.5349 - val_accuracy: 0.7561\n",
      "Epoch 840/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4617 - accuracy: 0.7699 - val_loss: 0.5353 - val_accuracy: 0.7480\n",
      "Epoch 841/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4632 - accuracy: 0.7719 - val_loss: 0.5350 - val_accuracy: 0.7561\n",
      "Epoch 842/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4614 - accuracy: 0.7739 - val_loss: 0.5348 - val_accuracy: 0.7561\n",
      "Epoch 843/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4619 - accuracy: 0.7719 - val_loss: 0.5348 - val_accuracy: 0.7561\n",
      "Epoch 844/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4620 - accuracy: 0.7719 - val_loss: 0.5349 - val_accuracy: 0.7480\n",
      "Epoch 845/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4618 - accuracy: 0.7678 - val_loss: 0.5349 - val_accuracy: 0.7561\n",
      "Epoch 846/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4622 - accuracy: 0.7719 - val_loss: 0.5349 - val_accuracy: 0.7561\n",
      "Epoch 847/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4624 - accuracy: 0.7699 - val_loss: 0.5349 - val_accuracy: 0.7561\n",
      "Epoch 848/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4626 - accuracy: 0.7699 - val_loss: 0.5349 - val_accuracy: 0.7561\n",
      "Epoch 849/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4616 - accuracy: 0.7719 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 850/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4615 - accuracy: 0.7739 - val_loss: 0.5349 - val_accuracy: 0.7561\n",
      "Epoch 851/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4616 - accuracy: 0.7699 - val_loss: 0.5352 - val_accuracy: 0.7480\n",
      "Epoch 852/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4621 - accuracy: 0.7739 - val_loss: 0.5349 - val_accuracy: 0.7561\n",
      "Epoch 853/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4612 - accuracy: 0.7678 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 854/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 855/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4629 - accuracy: 0.7658 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 856/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4612 - accuracy: 0.7719 - val_loss: 0.5350 - val_accuracy: 0.7561\n",
      "Epoch 857/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4619 - accuracy: 0.7719 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 858/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4614 - accuracy: 0.7739 - val_loss: 0.5350 - val_accuracy: 0.7561\n",
      "Epoch 859/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4617 - accuracy: 0.7719 - val_loss: 0.5350 - val_accuracy: 0.7561\n",
      "Epoch 860/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4612 - accuracy: 0.7739 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 861/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4615 - accuracy: 0.7719 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 862/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4617 - accuracy: 0.7719 - val_loss: 0.5352 - val_accuracy: 0.7480\n",
      "Epoch 863/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4619 - accuracy: 0.7699 - val_loss: 0.5350 - val_accuracy: 0.7561\n",
      "Epoch 864/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4616 - accuracy: 0.7678 - val_loss: 0.5350 - val_accuracy: 0.7561\n",
      "Epoch 865/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4617 - accuracy: 0.7719 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 866/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4612 - accuracy: 0.7678 - val_loss: 0.5356 - val_accuracy: 0.7480\n",
      "Epoch 867/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4616 - accuracy: 0.7739 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 868/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4624 - accuracy: 0.7699 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 869/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4616 - accuracy: 0.7658 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 870/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4610 - accuracy: 0.7699 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 871/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4609 - accuracy: 0.7678 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 872/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4610 - accuracy: 0.7678 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 873/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4612 - accuracy: 0.7719 - val_loss: 0.5352 - val_accuracy: 0.7480\n",
      "Epoch 874/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4614 - accuracy: 0.7699 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 875/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4610 - accuracy: 0.7719 - val_loss: 0.5357 - val_accuracy: 0.7561\n",
      "Epoch 876/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 877/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4615 - accuracy: 0.7719 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 878/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4611 - accuracy: 0.7719 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 879/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 880/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4617 - accuracy: 0.7699 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 881/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4608 - accuracy: 0.7699 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 882/1000\n",
      "491/491 [==============================] - 0s 28us/step - loss: 0.4606 - accuracy: 0.7719 - val_loss: 0.5351 - val_accuracy: 0.7561\n",
      "Epoch 883/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4614 - accuracy: 0.7739 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 884/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4605 - accuracy: 0.7719 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 885/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4615 - accuracy: 0.7739 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 886/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4605 - accuracy: 0.7699 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 887/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4609 - accuracy: 0.7719 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 888/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4611 - accuracy: 0.7719 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 889/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4628 - accuracy: 0.7658 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 890/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4606 - accuracy: 0.7719 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 891/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 892/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4609 - accuracy: 0.7719 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 893/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4610 - accuracy: 0.7739 - val_loss: 0.5359 - val_accuracy: 0.7561\n",
      "Epoch 894/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 895/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4612 - accuracy: 0.7719 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 896/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4610 - accuracy: 0.7719 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 897/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4607 - accuracy: 0.7739 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 898/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 899/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4611 - accuracy: 0.7678 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 900/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4606 - accuracy: 0.7719 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 901/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4609 - accuracy: 0.7719 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 902/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 903/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4603 - accuracy: 0.7719 - val_loss: 0.5353 - val_accuracy: 0.7642\n",
      "Epoch 904/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4607 - accuracy: 0.7739 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 905/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4607 - accuracy: 0.7739 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 906/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4608 - accuracy: 0.7719 - val_loss: 0.5357 - val_accuracy: 0.7561\n",
      "Epoch 907/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4615 - accuracy: 0.7739 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 908/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4605 - accuracy: 0.7739 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 909/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 910/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4606 - accuracy: 0.7739 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 911/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4608 - accuracy: 0.7739 - val_loss: 0.5356 - val_accuracy: 0.7561\n",
      "Epoch 912/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4604 - accuracy: 0.7739 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 913/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 914/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 915/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4608 - accuracy: 0.7699 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
      "Epoch 916/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.5353 - val_accuracy: 0.7480\n",
      "Epoch 917/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4607 - accuracy: 0.7760 - val_loss: 0.5353 - val_accuracy: 0.7480\n",
      "Epoch 918/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4618 - accuracy: 0.7739 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 919/1000\n",
      "491/491 [==============================] - ETA: 0s - loss: 0.3971 - accuracy: 0.80 - 0s 26us/step - loss: 0.4601 - accuracy: 0.7739 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 920/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.5359 - val_accuracy: 0.7561\n",
      "Epoch 921/1000\n",
      "491/491 [==============================] - 0s 29us/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 922/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 923/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4603 - accuracy: 0.7739 - val_loss: 0.5359 - val_accuracy: 0.7561\n",
      "Epoch 924/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.5357 - val_accuracy: 0.7561\n",
      "Epoch 925/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4600 - accuracy: 0.7739 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 926/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4598 - accuracy: 0.7719 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 927/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4603 - accuracy: 0.7719 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 928/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4605 - accuracy: 0.7719 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 929/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 930/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4602 - accuracy: 0.7699 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 931/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4601 - accuracy: 0.7780 - val_loss: 0.5359 - val_accuracy: 0.7561\n",
      "Epoch 932/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4605 - accuracy: 0.7739 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 933/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4613 - accuracy: 0.7719 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 934/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4601 - accuracy: 0.7780 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 935/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.5353 - val_accuracy: 0.7561\n",
      "Epoch 936/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.5356 - val_accuracy: 0.7480\n",
      "Epoch 937/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4610 - accuracy: 0.7719 - val_loss: 0.5355 - val_accuracy: 0.7480\n",
      "Epoch 938/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4603 - accuracy: 0.7780 - val_loss: 0.5354 - val_accuracy: 0.7480\n",
      "Epoch 939/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4597 - accuracy: 0.7719 - val_loss: 0.5357 - val_accuracy: 0.7561\n",
      "Epoch 940/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4598 - accuracy: 0.7800 - val_loss: 0.5354 - val_accuracy: 0.7642\n",
      "Epoch 941/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4601 - accuracy: 0.7739 - val_loss: 0.5357 - val_accuracy: 0.7561\n",
      "Epoch 942/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4604 - accuracy: 0.7821 - val_loss: 0.5355 - val_accuracy: 0.7642\n",
      "Epoch 943/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.5359 - val_accuracy: 0.7642\n",
      "Epoch 944/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.5361 - val_accuracy: 0.7642\n",
      "Epoch 945/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4599 - accuracy: 0.7780 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 946/1000\n",
      "491/491 [==============================] - 0s 27us/step - loss: 0.4599 - accuracy: 0.7780 - val_loss: 0.5354 - val_accuracy: 0.7480\n",
      "Epoch 947/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4601 - accuracy: 0.7780 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 948/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4598 - accuracy: 0.7780 - val_loss: 0.5355 - val_accuracy: 0.7642\n",
      "Epoch 949/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4596 - accuracy: 0.7760 - val_loss: 0.5354 - val_accuracy: 0.7642\n",
      "Epoch 950/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4599 - accuracy: 0.7760 - val_loss: 0.5355 - val_accuracy: 0.7480\n",
      "Epoch 951/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4598 - accuracy: 0.7739 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 952/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4597 - accuracy: 0.7760 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 953/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 954/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4595 - accuracy: 0.7821 - val_loss: 0.5356 - val_accuracy: 0.7561\n",
      "Epoch 955/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4594 - accuracy: 0.7760 - val_loss: 0.5354 - val_accuracy: 0.7642\n",
      "Epoch 956/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4599 - accuracy: 0.7739 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 957/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4596 - accuracy: 0.7800 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 958/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4597 - accuracy: 0.7760 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 959/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4606 - accuracy: 0.7739 - val_loss: 0.5362 - val_accuracy: 0.7561\n",
      "Epoch 960/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4603 - accuracy: 0.7780 - val_loss: 0.5355 - val_accuracy: 0.7642\n",
      "Epoch 961/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4609 - accuracy: 0.7780 - val_loss: 0.5360 - val_accuracy: 0.7642\n",
      "Epoch 962/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4617 - accuracy: 0.7739 - val_loss: 0.5357 - val_accuracy: 0.7561\n",
      "Epoch 963/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.5358 - val_accuracy: 0.7642\n",
      "Epoch 964/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4597 - accuracy: 0.7739 - val_loss: 0.5359 - val_accuracy: 0.7642\n",
      "Epoch 965/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.5356 - val_accuracy: 0.7480\n",
      "Epoch 966/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4610 - accuracy: 0.7739 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 967/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4597 - accuracy: 0.7760 - val_loss: 0.5361 - val_accuracy: 0.7642\n",
      "Epoch 968/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4599 - accuracy: 0.7800 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
      "Epoch 969/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4593 - accuracy: 0.7739 - val_loss: 0.5355 - val_accuracy: 0.7642\n",
      "Epoch 970/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4602 - accuracy: 0.7719 - val_loss: 0.5354 - val_accuracy: 0.7642\n",
      "Epoch 971/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.5354 - val_accuracy: 0.7642\n",
      "Epoch 972/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4599 - accuracy: 0.7800 - val_loss: 0.5354 - val_accuracy: 0.7642\n",
      "Epoch 973/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4593 - accuracy: 0.7841 - val_loss: 0.5359 - val_accuracy: 0.7642\n",
      "Epoch 974/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4614 - accuracy: 0.7841 - val_loss: 0.5357 - val_accuracy: 0.7642\n",
      "Epoch 975/1000\n",
      "491/491 [==============================] - 0s 25us/step - loss: 0.4599 - accuracy: 0.7739 - val_loss: 0.5353 - val_accuracy: 0.7642\n",
      "Epoch 976/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4596 - accuracy: 0.7780 - val_loss: 0.5353 - val_accuracy: 0.7480\n",
      "Epoch 977/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4596 - accuracy: 0.7760 - val_loss: 0.5354 - val_accuracy: 0.7642\n",
      "Epoch 978/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4594 - accuracy: 0.7780 - val_loss: 0.5354 - val_accuracy: 0.7480\n",
      "Epoch 979/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4593 - accuracy: 0.7800 - val_loss: 0.5353 - val_accuracy: 0.7480\n",
      "Epoch 980/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4595 - accuracy: 0.7800 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
      "Epoch 981/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4601 - accuracy: 0.7780 - val_loss: 0.5355 - val_accuracy: 0.7642\n",
      "Epoch 982/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4591 - accuracy: 0.7800 - val_loss: 0.5354 - val_accuracy: 0.7480\n",
      "Epoch 983/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.5354 - val_accuracy: 0.7480\n",
      "Epoch 984/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.5354 - val_accuracy: 0.7642\n",
      "Epoch 985/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.5354 - val_accuracy: 0.7642\n",
      "Epoch 986/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4596 - accuracy: 0.7821 - val_loss: 0.5354 - val_accuracy: 0.7480\n",
      "Epoch 987/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4591 - accuracy: 0.7780 - val_loss: 0.5354 - val_accuracy: 0.7642\n",
      "Epoch 988/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4598 - accuracy: 0.7780 - val_loss: 0.5356 - val_accuracy: 0.7642\n",
      "Epoch 989/1000\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.4594 - accuracy: 0.7780 - val_loss: 0.5357 - val_accuracy: 0.7642\n",
      "Epoch 990/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4595 - accuracy: 0.7821 - val_loss: 0.5357 - val_accuracy: 0.7642\n",
      "Epoch 991/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4594 - accuracy: 0.7821 - val_loss: 0.5356 - val_accuracy: 0.7561\n",
      "Epoch 992/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4603 - accuracy: 0.7821 - val_loss: 0.5356 - val_accuracy: 0.7561\n",
      "Epoch 993/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4592 - accuracy: 0.7760 - val_loss: 0.5355 - val_accuracy: 0.7642\n",
      "Epoch 994/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4591 - accuracy: 0.7739 - val_loss: 0.5356 - val_accuracy: 0.7480\n",
      "Epoch 995/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4595 - accuracy: 0.7780 - val_loss: 0.5355 - val_accuracy: 0.7642\n",
      "Epoch 996/1000\n",
      "491/491 [==============================] - 0s 31us/step - loss: 0.4591 - accuracy: 0.7719 - val_loss: 0.5355 - val_accuracy: 0.7642\n",
      "Epoch 997/1000\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.4598 - accuracy: 0.7780 - val_loss: 0.5357 - val_accuracy: 0.7480\n",
      "Epoch 998/1000\n",
      "491/491 [==============================] - 0s 22us/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.5355 - val_accuracy: 0.7480\n",
      "Epoch 999/1000\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.4592 - accuracy: 0.7760 - val_loss: 0.5355 - val_accuracy: 0.7642\n",
      "Epoch 1000/1000\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.4588 - accuracy: 0.7739 - val_loss: 0.5356 - val_accuracy: 0.7642\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "hist = model.fit(x_train, y_train, batch_size = 57, epochs = 1000, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visulise the training and validation loss to see if the model is overfitting\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visulise the training and validation accuracy to see if the model is overfitting\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
      "[0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction and predict the actual values\n",
    "prediction = model.predict(x_test)\n",
    "prediction = [1 if y>= 0.5 else 0 for y in prediction] \n",
    "print(prediction)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.87      0.84       398\n",
      "         1.0       0.72      0.60      0.65       216\n",
      "\n",
      "    accuracy                           0.78       614\n",
      "   macro avg       0.76      0.74      0.74       614\n",
      "weighted avg       0.77      0.78      0.77       614\n",
      "\n",
      "confusion_matrix: \n",
      " [[348  50]\n",
      " [ 87 129]]\n",
      "\n",
      "Accuracy: 0.7768729641693811\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "pred = model.predict(x_train)\n",
    "pred = [1 if y>= 0.5 else 0 for y in pred] \n",
    "print(classification_report(y_train, pred))\n",
    "print('confusion_matrix: \\n', confusion_matrix(y_train, pred))\n",
    "print()\n",
    "print('Accuracy:', accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.83      0.83       102\n",
      "         1.0       0.67      0.67      0.67        52\n",
      "\n",
      "    accuracy                           0.78       154\n",
      "   macro avg       0.75      0.75      0.75       154\n",
      "weighted avg       0.78      0.78      0.78       154\n",
      "\n",
      "confusion_matrix: \n",
      " [[85 17]\n",
      " [17 35]]\n",
      "\n",
      "Accuracy: 0.7792207792207793\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "pred = [1 if y>= 0.5 else 0 for y in pred] \n",
    "print(classification_report(y_test, pred))\n",
    "print('confusion_matrix: \\n', confusion_matrix(y_test, pred))\n",
    "print()\n",
    "print('Accuracy:', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
